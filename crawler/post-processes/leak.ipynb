{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfdcf092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base16: 68656C6C6F20776F726C64\n",
      "base32: NBSWY3DPEB3W64TMMQ======\n",
      "base58: StV1DL6CwTryKyV\n",
      "base64: aGVsbG8gd29ybGQ=\n",
      "urlencode: hello+world\n",
      "deflate: cb48cdc9c95728cf2fca490100\n",
      "zlib: 789ccb48cdc9c95728cf2fca4901001a0b045d\n",
      "gzip: 1f8b0800000000000013cb48cdc9c95728cf2fca49010085114a0d0b000000\n",
      "binary: 0110100001100101011011000110110001101111001000000111011101101111011100100110110001100100\n",
      "entity: hello world\n",
      "rot13: uryyb jbeyq\n",
      "deflate_base64: y0jNyclXKM8vykkBAA==\n",
      "deflateraw_base64: y0jNyclXKM8vykkBAA==\n",
      "gzip_base64: H4sIAAAAAAAAE8tIzcnJVyjPL8pJAQCFEUoNCwAAAA==\n",
      "brotli_base64: CwWAaGVsbG8gd29ybGQD\n",
      "deflate_hex: cb48cdc9c95728cf2fca490100\n",
      "gzip_hex: 1f8b0800000000000013cb48cdc9c95728cf2fca49010085114a0d0b000000\n",
      "zlib64: eJzLSM3JyVcozy/KSQEAGgsEXQ==\n",
      "lz64: 1oXjgLbmg7ZA7rqQ4pyw04gA\n",
      "lz64de: 1oXjgLbmg7ZA7rqQ4pyw04gA\n",
      "lz_string: BYUwNmD2AEDukCcwBMg\n",
      "md5: 5eb63bbbe01eeed093cb22bb8f5acdc3\n",
      "sha1: 2aae6c35c94fcfb415dbe95f408b9ce91ee846ed\n",
      "sha256: b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9\n",
      "sha224: 2f05477fc24bb4faefd86517156dafdecec45b8ad3cf2522a563582b\n",
      "sha384: fdbd8e75a67f29f701a4e040385e2e23986303ea10239211af907fcbb83578b3e417cb71ce646efd0819dd8c088de1bd\n",
      "sha512: 309ecc489c12d6eb4cc40f50c902f2b4d0ed77ee511a7c7a9bcd3ca86d4cd86f989dd35bc5ff499670da34255b45b0cfd830e81f605dcf7dc5542e93ae9cd76f\n",
      "sha3_224: dfb7f18c77e928bb56faeb2da27291bd790bc1045cde45f3210bb6c5\n",
      "sha3_256: 644bcc7e564373040999aac89e7622f3ca71fba1d972fd94a31c3bfbf24e3938\n",
      "sha3_384: 83bff28dde1b1bf5810071c6643c08e5b05bdb836effd70b403ea8ea0a634dc4997eb1053aa3593f590f9c63630dd90b\n",
      "sha3_512: 840006653e9ac9e95117a15c915caab81662918e925de9e004f774ff82d7079a40d4d27b1b372657c61d46d470304c88c788b3a4527ad074d1dccbee5dbaa99a\n",
      "mmh3_32: 1586663183\n",
      "mmh3_64_1: 5998619086395760910\n",
      "mmh3_64_2: -6082315267429669967\n",
      "mmh3_128: 228083453807047072434243676435732455694\n",
      "crc32: 222957957\n",
      "adler32: 436929629\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import base58\n",
    "import zlib\n",
    "import json\n",
    "import html\n",
    "import codecs\n",
    "import brotli\n",
    "from urllib.parse import quote_plus\n",
    "from lzstring import LZString\n",
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import hashlib\n",
    "import mmh3\n",
    "import mmh as mmhash\n",
    "import base64\n",
    "import base58\n",
    "import zlib\n",
    "import json\n",
    "import re\n",
    "from urllib.parse import quote_plus, unquote_plus\n",
    "import codecs\n",
    "\n",
    "from lzstring import LZString\n",
    "import html\n",
    "import brotli\n",
    "import lzma\n",
    "import brotli\n",
    "\n",
    "\n",
    "\n",
    "def rot_n(text, n):\n",
    "    result = []\n",
    "    for char in text:\n",
    "        if 'a' <= char <= 'z':\n",
    "            result.append(chr((ord(char) - ord('a') + n) % 26 + ord('a')))\n",
    "        elif 'A' <= char <= 'Z':\n",
    "            result.append(chr((ord(char) - ord('A') + n) % 26 + ord('A')))\n",
    "        else:\n",
    "            result.append(char)\n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "def compress_with_zlib(compression_type, string, level=6):\n",
    "    if compression_type == 'deflate':\n",
    "        compressor = zlib.compressobj(level, zlib.DEFLATED, -zlib.MAX_WBITS)\n",
    "    elif compression_type == 'zlib':\n",
    "        compressor = zlib.compressobj(level, zlib.DEFLATED, zlib.MAX_WBITS)\n",
    "    elif compression_type == 'gzip':\n",
    "        compressor = zlib.compressobj(level, zlib.DEFLATED, zlib.MAX_WBITS | 16)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported zlib compression format: {compression_type}\")\n",
    "    return compressor.compress(string) + compressor.flush()\n",
    "\n",
    "\n",
    "def create_variations(input_string):\n",
    "    x_bytes = input_string.encode('utf-8')\n",
    "    x_str = input_string\n",
    "    results = {}\n",
    "\n",
    "    encodings = {\n",
    "        'base16': lambda x: base64.b16encode(x),\n",
    "        'base32': lambda x: base64.b32encode(x),\n",
    "        'base58': lambda x: base58.b58encode(x),\n",
    "        'base64': lambda x: base64.b64encode(x),\n",
    "        'urlencode': lambda x: quote_plus(x_str),\n",
    "        'deflate': lambda x: compress_with_zlib('deflate', x),\n",
    "        'zlib': lambda x: compress_with_zlib('zlib', x),\n",
    "        'gzip': lambda x: compress_with_zlib('gzip', x), \n",
    "        'binary': lambda x: ''.join(format(b, '08b') for b in x),\n",
    "        'entity': lambda x: html.escape(x_str),\n",
    "        'rot13': lambda x: codecs.encode(x_str, 'rot_13'),\n",
    "        'deflate_base64': lambda x: base64.b64encode(compress_with_zlib('deflate', x)),\n",
    "        'deflateraw_base64': lambda x: base64.b64encode(compress_with_zlib('deflate', x)),\n",
    "        'gzip_base64': lambda x: base64.b64encode(compress_with_zlib('gzip', x)),\n",
    "        'brotli_base64': lambda x: base64.b64encode(brotli.compress(x)),\n",
    "        'deflate_hex': lambda x: compress_with_zlib('deflate', x).hex(),\n",
    "        'gzip_hex': lambda x: compress_with_zlib('gzip', x).hex(),\n",
    "        'zlib64': lambda x: base64.b64encode(zlib.compress(x)).decode('utf-8')\n",
    "    }  \n",
    "\n",
    "    # Optional encodings (wrapped in try-except)\n",
    "    try:\n",
    "        lz = LZString()\n",
    "        encodings['lz64'] = lambda x: base64.b64encode(lz.compress(x_str).encode('utf-8'))\n",
    "        encodings['lz64de'] = lambda x: base64.b64encode(lz.compress(x_str).encode('utf-8')).decode()\n",
    "        encodings['lz_string'] = lambda x: lz.compressToEncodedURIComponent(x_str)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        import lzw\n",
    "        encodings['lzw'] = lambda x: json.dumps(lzw.encode(x_str))\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    hashes = dict()\n",
    "    # hashes['md2'] = lambda x: self._get_md2_hash(x)\n",
    "    encodings['md5'] = lambda x: hashlib.md5(x).hexdigest()\n",
    "    encodings['sha1'] = lambda x: hashlib.sha1(x).hexdigest()\n",
    "    encodings['sha256'] = lambda x: hashlib.sha256(x).hexdigest()\n",
    "    encodings['sha224'] = lambda x: hashlib.sha224(x).hexdigest()\n",
    "    encodings['sha384'] = lambda x: hashlib.sha384(x).hexdigest()\n",
    "    encodings['sha512'] = lambda x: hashlib.sha512(x).hexdigest()\n",
    "    encodings['sha3_224'] = lambda x: hashlib.sha3_224(x if isinstance(x, bytes) else x.encode('utf-8')).hexdigest()\n",
    "    encodings['sha3_256'] = lambda x: hashlib.sha3_256(x if isinstance(x, bytes) else x.encode('utf-8')).hexdigest()\n",
    "    encodings['sha3_384'] = lambda x: hashlib.sha3_384(x if isinstance(x, bytes) else x.encode('utf-8')).hexdigest()\n",
    "    encodings['sha3_512'] = lambda x: hashlib.sha3_512(x if isinstance(x, bytes) else x.encode('utf-8')).hexdigest()\n",
    "    encodings['mmh3_32'] = lambda x: str(mmh3.hash(x))\n",
    "    encodings['mmh3_64_1'] = lambda x: str(mmh3.hash64(x)[0])\n",
    "    encodings['mmh3_64_2'] = lambda x: str(mmh3.hash64(x)[1])\n",
    "    encodings['mmh3_128'] = lambda x: str(mmh3.hash128(x))\n",
    "    # hashes['blake2b'] = lambda x: pyblake2.blake2b(x).hexdigest()\n",
    "    # hashes['blake2s'] = lambda x: pyblake2.blake2s(x).hexdigest()\n",
    "    encodings['crc32'] = lambda x: str(zlib.crc32(x) & 0xFFFFFFFF)\n",
    "    encodings['adler32'] = lambda x: str(zlib.adler32(x))\n",
    " \n",
    "    \n",
    "    \n",
    "    # Apply all encodings\n",
    "    for name, func in encodings.items():\n",
    "        try:\n",
    "            result = func(x_bytes)\n",
    "            if isinstance(result, bytes):\n",
    "                try:\n",
    "                    results[name] = result.decode('utf-8')\n",
    "                except UnicodeDecodeError:\n",
    "                    results[name] = result.hex()\n",
    "            else:\n",
    "                results[name] = result\n",
    "        except Exception as e:\n",
    "            results[name] = f'ERROR: {str(e)}'\n",
    "            \n",
    "    return results\n",
    "\n",
    "\n",
    "# ðŸ”½ Run and print results\n",
    "encoded = create_variations(\"hello world\")\n",
    "for k, v in encoded.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35903fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Checking URL ===\n",
      "URL tokens:\n",
      "{'aGlfbXk', '123', 'profile', 'token', 'id'}\n",
      "aGlfbXk\n",
      "123\n",
      "profile\n",
      "token\n",
      "id\n",
      "\n",
      "URL parameters:\n",
      "Tokens: set()\n",
      "Parameters: set()\n",
      "Leaks found in URL: [('base64', 'hi_my')]\n",
      "Leaks found in Payload: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:25: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:381: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:382: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:381: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:382: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/var/folders/pw/cc8d4lgn471dtgys03f89hk80000gn/T/ipykernel_36801/1621865594.py:25: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  EXTENSION_RE = re.compile('\\.[A-Za-z]{2,4}$')\n",
      "/var/folders/pw/cc8d4lgn471dtgys03f89hk80000gn/T/ipykernel_36801/1621865594.py:381: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  strings.append(re.sub('\\.', '', uname))\n",
      "/var/folders/pw/cc8d4lgn471dtgys03f89hk80000gn/T/ipykernel_36801/1621865594.py:382: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  strings.append(re.sub('\\.', '', uname) + '@' + domain)\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import hashlib\n",
    "import mmh3\n",
    "import mmh as mmhash\n",
    "import base64\n",
    "import base58\n",
    "import zlib\n",
    "import json\n",
    "import re\n",
    "from urllib.parse import quote_plus, unquote_plus\n",
    "import codecs\n",
    "\n",
    "from lzstring import LZString\n",
    "import html\n",
    "import brotli\n",
    "import lzma\n",
    "import brotli\n",
    "\n",
    "\n",
    "# DELIMITERS = re.compile('[&|\\,]')\n",
    "DELIMITERS = re.compile(r'[&|,=]')\n",
    "\n",
    "EXTENSION_RE = re.compile('\\.[A-Za-z]{2,4}$')\n",
    "ENCODING_LAYERS = 3\n",
    "ENCODINGS_NO_ROT = ['base64', 'base32', 'base16',\n",
    "    'base58', 'zlib', 'gzip', 'urlencode',\n",
    "    'entity', 'zlib64', 'brotli_base64', 'json',\n",
    "    'deflate_base64', 'deflateraw_base64', 'gzip_base64',\n",
    "    'hex' ]\n",
    "LIKELY_ENCODINGS = ['base16', 'base32', 'base58', 'base64',\n",
    "                    'urlencode',  'entity', 'zlib64']\n",
    "HASHES = [  'md5', 'sha1', 'sha256', 'sha224', 'sha384',\n",
    "          'sha512', 'sha3_224', 'sha3_256', 'sha3_384', 'sha3_512',   'mmh3_32', 'mmh3_64_1', 'mmh3_64_2', 'mmh3_128',  ]\n",
    "\n",
    "\n",
    "class Hasher():\n",
    "    def __init__(self):\n",
    "        # Define Supported hashes\n",
    "        hashes = dict()\n",
    "        # hashes['md2'] = lambda x: self._get_md2_hash(x)\n",
    "        hashes['md5'] = lambda x: hashlib.md5(x).hexdigest()\n",
    "        hashes['sha1'] = lambda x: hashlib.sha1(x).hexdigest()\n",
    "        hashes['sha256'] = lambda x: hashlib.sha256(x).hexdigest()\n",
    "        hashes['sha224'] = lambda x: hashlib.sha224(x).hexdigest()\n",
    "        hashes['sha384'] = lambda x: hashlib.sha384(x).hexdigest()\n",
    "        hashes['sha512'] = lambda x: hashlib.sha512(x).hexdigest()\n",
    "        hashes['sha3_224'] = lambda x: hashlib.sha3_224(x if isinstance(x, bytes) else x.encode('utf-8')).hexdigest()\n",
    "        hashes['sha3_256'] = lambda x: hashlib.sha3_256(x if isinstance(x, bytes) else x.encode('utf-8')).hexdigest()\n",
    "        hashes['sha3_384'] = lambda x: hashlib.sha3_384(x if isinstance(x, bytes) else x.encode('utf-8')).hexdigest()\n",
    "        hashes['sha3_512'] = lambda x: hashlib.sha3_512(x if isinstance(x, bytes) else x.encode('utf-8')).hexdigest()\n",
    "        hashes['mmh3_32'] = lambda x: str(mmh3.hash(x))\n",
    "        hashes['mmh3_64_1'] = lambda x: str(mmh3.hash64(x)[0])\n",
    "        hashes['mmh3_64_2'] = lambda x: str(mmh3.hash64(x)[1])\n",
    "        hashes['mmh3_128'] = lambda x: str(mmh3.hash128(x))\n",
    "       # hashes['blake2b'] = lambda x: pyblake2.blake2b(x).hexdigest()\n",
    "       # hashes['blake2s'] = lambda x: pyblake2.blake2s(x).hexdigest()\n",
    "        hashes['crc32'] = lambda x: str(zlib.crc32(x) & 0xFFFFFFFF)\n",
    "        hashes['adler32'] = lambda x: str(zlib.adler32(x))\n",
    "\n",
    "        self._hashes = hashes\n",
    "        self.hashes_and_checksums = list(self._hashes.keys())\n",
    "        self.supported_hashes = HASHES\n",
    "\n",
    "    def _get_hashlib_hash(self, name, string):\n",
    "        \"\"\"Use for hashlib hashes that don't have a shortcut\"\"\"\n",
    "        hasher = hashlib.new(name)\n",
    "        hasher.update(string)\n",
    "        return hasher.hexdigest()\n",
    "\n",
    "    def _get_md2_hash(self, string):\n",
    "        \"\"\"Compute md2 hash\"\"\"\n",
    "        md2 = MD2.new()\n",
    "        md2.update(string)\n",
    "        return md2.hexdigest()\n",
    "\n",
    "    def get_hash(self, hash_name, string):\n",
    "        \"\"\"Compute the desired hash\"\"\"\n",
    "        return self._hashes[hash_name](string)\n",
    "\n",
    "\n",
    "class Encoder():\n",
    "    def __init__(self):\n",
    "        # Define supported encodings\n",
    "        encodings = dict()\n",
    "        encodings['base16'] = lambda x: base64.b16encode(x)\n",
    "        encodings['base32'] = lambda x: base64.b32encode(x)\n",
    "        encodings['base58'] = lambda x: base58.b58encode(x)\n",
    "        encodings['base64'] = lambda x: base64.b64encode(x)\n",
    "        encodings['urlencode'] = lambda x: quote_plus(x)\n",
    "        encodings['deflate'] = lambda x: self._compress_with_zlib('deflate', x)\n",
    "        encodings['zlib'] = lambda x: self._compress_with_zlib('zlib', x)\n",
    "        encodings['gzip'] = lambda x: self._compress_with_zlib('gzip', x)\n",
    "        encodings['json'] = lambda x: json.dumps(x)\n",
    "        encodings['binary'] = lambda x: ''.join(format(ord(c), '08b') for c in x)\n",
    "        encodings['entity'] = lambda x: html.escape(x)\n",
    "        encodings['rot13'] = lambda x: codecs.encode(x, 'rot_13')\n",
    "        \n",
    "        for i in range(1, 26):\n",
    "            if i == 13:\n",
    "                continue  # handled separately with codecs\n",
    "            encodings[f'rot{i}'] = lambda x, i=i: rot_n(x, i)\n",
    " \n",
    "        encodings['deflate_base64'] = lambda x: base64.b64encode(zlib.compress(x))\n",
    "        encodings['deflateraw_base64'] = lambda x: base64.b64encode(zlib.compress(x, -zlib.MAX_WBITS))\n",
    "        encodings['gzip_base64'] = lambda x: base64.b64encode(zlib.compress(x, zlib.MAX_WBITS | 16))\n",
    "        encodings['brotli_base64'] = lambda x: base64.b64encode(brotli.compress(x))\n",
    "        encodings['deflate_hex'] = lambda x: zlib.compress(x).hex()\n",
    "        encodings['gzip_hex'] = lambda x: zlib.compress(x, zlib.MAX_WBITS | 16).hex()\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            lz = LZString()\n",
    "            encodings['lz64'] = lambda x: base64.b64encode(lz.compress(x.decode('utf-8')).encode('utf-8'))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            lz = LZString()\n",
    "            encodings['lz64de'] = lambda x: base64.b64encode(LZString().compress(x.decode('utf-8')).encode('utf-8')).decode('utf-8')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        encodings['zlib64'] = lambda x: base64.b64encode(zlib.compress(x.encode('utf-8') if isinstance(x, str) else x)).decode('utf-8')\n",
    "        \n",
    "        try:\n",
    "            import lzw\n",
    "            encodings['lzw'] = lambda x: json.dumps(lzw.encode(x.decode('utf-8')))\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            lz = LZString()\n",
    "            encodings['lz_string'] = lambda x: lz.compressToEncodedURIComponent(x.decode('utf-8'))\n",
    "        except:\n",
    "            pass\n",
    "        self._encodings = encodings\n",
    "        self.supported_encodings = list(self._encodings.keys())\n",
    "\n",
    "    def _compress_with_zlib(self, compression_type, string, level=6):\n",
    "        \"\"\"Compress in one of the zlib supported formats: zlib, gzip, or deflate.\n",
    "        For a description see: http://stackoverflow.com/a/22311297/6073564\n",
    "        \"\"\"\n",
    "        if compression_type == 'deflate':\n",
    "            compressor = zlib.compressobj(level, zlib.DEFLATED,\n",
    "                                          -zlib.MAX_WBITS)\n",
    "        elif compression_type == 'zlib':\n",
    "            compressor = zlib.compressobj(level, zlib.DEFLATED,\n",
    "                                          zlib.MAX_WBITS)\n",
    "        elif compression_type == 'gzip':\n",
    "            compressor = zlib.compressobj(level, zlib.DEFLATED,\n",
    "                                          zlib.MAX_WBITS | 16)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported zlib compression format %s.\" %\n",
    "                             compression_type)\n",
    "        return compressor.compress(string) + compressor.flush()\n",
    "\n",
    "    def encode(self, encoding, string):\n",
    "        \"\"\"Encode `string` in desired `encoding`\"\"\"\n",
    "        return self._encodings[encoding](string)\n",
    "\n",
    "\n",
    "class DecodeException(Exception):\n",
    "    def __init__(self, message, error):\n",
    "        super(DecodeException, self).__init__(message)\n",
    "        self.error = error\n",
    "\n",
    "\n",
    "def rot_n(text, n):\n",
    "    def rotate_char(c):\n",
    "        if 'a' <= c <= 'z':\n",
    "            return chr((ord(c) - ord('a') + n) % 26 + ord('a'))\n",
    "        elif 'A' <= c <= 'Z':\n",
    "            return chr((ord(c) - ord('A') + n) % 26 + ord('A'))\n",
    "        return c\n",
    "    return ''.join(rotate_char(c) for c in text)\n",
    "\n",
    "class Decoder():\n",
    "    def __init__(self):\n",
    "        # Define supported encodings\n",
    "        decodings = dict()\n",
    "        decodings['base16'] = lambda x: base64.b16decode(x)\n",
    "        decodings['base32'] = lambda x: base64.b32decode(x)\n",
    "        decodings['base58'] = lambda x: base58.b58decode(x)\n",
    "        decodings['base64'] = lambda x: base64.b64decode(x)\n",
    "        decodings['urlencode'] = lambda x: unquote_plus(x)\n",
    "        decodings['deflate'] = lambda x: self._decompress_with_zlib('deflate',\n",
    "                                                                    x)\n",
    "        decodings['zlib'] = lambda x: self._decompress_with_zlib('zlib', x)\n",
    "        decodings['gzip'] = lambda x: self._decompress_with_zlib('gzip', x)\n",
    "        decodings['json'] = lambda x: json.loads(x)\n",
    "        decodings['binary'] = lambda x: ''.join(chr(int(x[i:i+8], 2)) for i in range(0, len(x), 8))\n",
    "        decodings['entity'] = lambda x: html.unescape(x)\n",
    "        \n",
    "        decodings['rot13'] = lambda x: codecs.decode(x, 'rot_13')\n",
    "        \n",
    "        for i in range(1, 26):\n",
    "            if i == 13:\n",
    "                continue  # handled separately with codecs\n",
    "            decodings[f'rot{i}'] = lambda x, i=i: rot_n(x, i)\n",
    "            \n",
    "        try:\n",
    "            lz = LZString()\n",
    "            decodings['lz64'] = lambda x: lz.decompress(base64.b64decode(x).decode('utf-8'))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        decodings['zlib64'] = lambda x: zlib.decompress(base64.b64decode(x)).decode('utf-8', errors='ignore')\n",
    "        \n",
    "        try:\n",
    "            lz = LZString()\n",
    "            decodings['lz64de'] = lambda x: LZString().decompress(base64.b64decode(x).decode('utf-8'))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            lz = LZString()\n",
    "            decodings['lz_string'] = lambda x: lz.decompressFromEncodedURIComponent(x)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            \n",
    "            import lzw\n",
    "            decodings['lzw'] = lambda x: ''.join(lzw.decode(json.loads(x)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            decodings['brotli_base64'] = lambda x: brotli.decompress(base64.b64decode(x)).decode('utf-8', errors='ignore')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        decodings['deflate_base64'] = lambda x: zlib.decompress(base64.b64decode(x), -zlib.MAX_WBITS).decode('utf-8', errors='ignore')\n",
    "        decodings['deflateraw_base64'] = lambda x: zlib.decompress(base64.b64decode(x), -zlib.MAX_WBITS).decode('utf-8', errors='ignore')\n",
    "        decodings['gzip_base64'] = lambda x: zlib.decompress(base64.b64decode(x), zlib.MAX_WBITS | 16).decode('utf-8', errors='ignore')\n",
    "        decodings['deflate_hex'] = lambda x: zlib.decompress(bytes.fromhex(x)).decode('utf-8', errors='ignore')\n",
    "        decodings['gzip_hex'] = lambda x: zlib.decompress(bytes.fromhex(x), zlib.MAX_WBITS | 16).decode('utf-8', errors='ignore')\n",
    " \n",
    "        self._decodings = decodings\n",
    "        self.supported_encodings = list(self._decodings.keys())\n",
    "\n",
    "    def _decompress_with_zlib(self, compression_type, string, level=9):\n",
    "        \"\"\"Compress in one of the zlib supported formats: zlib, gzip, or deflate.\n",
    "        For a description see: http://stackoverflow.com/a/22311297/6073564\n",
    "        \"\"\"\n",
    "        if compression_type == 'deflate':\n",
    "            return zlib.decompress(string, -zlib.MAX_WBITS)\n",
    "        elif compression_type == 'zlib':\n",
    "            return zlib.decompress(string, zlib.MAX_WBITS)\n",
    "        elif compression_type == 'gzip':\n",
    "            return zlib.decompress(string, zlib.MAX_WBITS | 16)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported zlib compression format %s.\" %\n",
    "                             compression_type)\n",
    "\n",
    "    def decode_error(self):\n",
    "        \"\"\"Catch-all error for all supported decoders\"\"\"\n",
    "\n",
    "    def decode(self, encoding, string):\n",
    "        \"\"\"Decode `string` encoded by `encoding`\"\"\"\n",
    "        try:\n",
    "            return self._decodings[encoding](string)\n",
    "        except Exception as e:\n",
    "            raise DecodeException(\n",
    "                'Error while trying to decode %s' % encoding,\n",
    "                e\n",
    "            )\n",
    "\n",
    "\n",
    "class LeakDetector():\n",
    "    def __init__(self, search_strings, precompute_hashes=True, hash_set=None,\n",
    "                 hash_layers=2, precompute_encodings=True, encoding_set=None,\n",
    "                 encoding_layers=2, debugging=False):\n",
    "        \"\"\"LeakDetector searches URL, POST bodies, and cookies for leaks.\n",
    "\n",
    "        The detector is constructed with a set of search strings (given by\n",
    "        the `search_strings` parameters. It has several methods to check for\n",
    "        leaks containing these strings in URLs, POST bodies, and cookie header\n",
    "        strings.\n",
    "\n",
    "        Parameters\n",
    "        ==========\n",
    "        search_strings : list\n",
    "            LeakDetector will search for leaks containing any item in this list\n",
    "        precompute_hashes : bool\n",
    "            Set to `True` to include precomputed hashes in the candidate set.\n",
    "        hash_set : list\n",
    "            List of hash functions to use when building the set of candidate\n",
    "            strings.\n",
    "        hash_layers : int\n",
    "            The detector will find instances of `search_string` iteratively\n",
    "            hashed up to `hash_layers` times by any combination of supported\n",
    "            hashes.\n",
    "        precompute_encodings : bool\n",
    "            Set to `True` to include precomputed encodings in the candidate set\n",
    "        encoding_set : list\n",
    "            List of encodings to use when building the set of candidate\n",
    "            strings.\n",
    "        encoding_layers : int\n",
    "            The detector will find instances of `search_string` iteratively\n",
    "            encoded up to `encoding_layers` times by any combination of\n",
    "            supported encodings.\n",
    "        debugging : bool\n",
    "            Set to `True` to enable a verbose output.\n",
    "        \"\"\"\n",
    "        self.search_strings = search_strings\n",
    "        self._min_length = min([len(x) for x in search_strings])\n",
    "        self._hasher = Hasher()\n",
    "        self._hash_set = hash_set\n",
    "        self._hash_layers = hash_layers\n",
    "        self._encoder = Encoder()\n",
    "        self._encoding_set = encoding_set\n",
    "        self._encoding_layers = encoding_layers\n",
    "        self._decoder = Decoder()\n",
    "        self._precompute_pool = dict()\n",
    "        # If hash/encoding sets aren't specified, use all available.\n",
    "        if self._hash_set is None:\n",
    "            self._hash_set = self._hasher.supported_hashes\n",
    "        if self._encoding_set is None:\n",
    "            self._encoding_set = self._encoder.supported_encodings\n",
    "        self._build_precompute_pool(precompute_hashes, precompute_encodings)\n",
    "        self._debugging = debugging\n",
    "\n",
    "    def _compute_hashes(self, string, layers, prev_hashes=tuple()):\n",
    "        \"\"\"Returns all iterative hashes of `string` up to the\n",
    "        specified number of `layers`\"\"\"\n",
    "        for h in self._hasher.supported_hashes:\n",
    "            hashed_string = self._hasher.get_hash(h, string.encode('utf-8'))\n",
    "            if hashed_string == string:  # skip no-ops\n",
    "                continue\n",
    "            hash_stack = (h,) + prev_hashes\n",
    "            self._precompute_pool[hashed_string] = hash_stack\n",
    "            if layers > 1:\n",
    "                self._compute_hashes(hashed_string, layers-1, hash_stack)\n",
    "\n",
    "    def _compute_encodings(self, string, layers, prev_encodings=tuple()):\n",
    "        for enc in self._encoding_set:\n",
    "            try:\n",
    "                input_data = string.encode('utf-8') if enc in ['base16', 'base32', 'base58', 'base64', 'deflate', 'zlib', 'gzip'] else string\n",
    "                encoded = self._encoder.encode(enc, input_data)\n",
    "                if isinstance(encoded, bytes):\n",
    "                    encoded_string = encoded.decode('utf-8', errors='ignore')\n",
    "                else:\n",
    "                    encoded_string = str(encoded)\n",
    "            except Exception:\n",
    "                continue\n",
    "            if encoded_string == string:\n",
    "                continue\n",
    "            encoding_stack = (enc,) + prev_encodings\n",
    "            self._precompute_pool[encoded_string] = encoding_stack\n",
    "            if layers > 1:\n",
    "                self._compute_encodings(encoded_string, layers - 1, encoding_stack)\n",
    "\n",
    "    def _build_precompute_pool(self, precompute_hashes, precompute_encodings):\n",
    "        \"\"\"Build a pool of hashes for the given search string\"\"\"\n",
    "        seed_strings = list()\n",
    "        for string in self.search_strings:\n",
    "            seed_strings.append(string)\n",
    "            if string.startswith('http'):\n",
    "                continue\n",
    "            all_lower = string.lower()\n",
    "            if all_lower != string:\n",
    "                seed_strings.append(string.lower())\n",
    "            all_upper = string.upper()\n",
    "            if all_upper != string:\n",
    "                seed_strings.append(string.upper())\n",
    "\n",
    "        strings = list()\n",
    "        for string in seed_strings:\n",
    "            strings.append(string)\n",
    "            # If the search string appears to be an email address, we also want\n",
    "            # to include just the username portion of the URL, and the address\n",
    "            # and username with any '.'s removed from the username (since these\n",
    "            # are optional in Gmail).\n",
    "            if '@' in string:\n",
    "                parts = string.rsplit('@')\n",
    "                if len(parts) == 2:\n",
    "                    uname, domain = parts\n",
    "                    strings.append(uname)\n",
    "                    strings.append(re.sub('\\.', '', uname))\n",
    "                    strings.append(re.sub('\\.', '', uname) + '@' + domain)\n",
    "                # Domain searches have too many false positives\n",
    "                # strings.append(parts[1])\n",
    "                # strings.append(parts[1].rsplit('.', 1)[0])\n",
    "            # The URL tokenizer strips file extensions. So if our search string\n",
    "            # has a file extension we should also search for a stripped version\n",
    "            if re.match(EXTENSION_RE, string):\n",
    "                strings.append(re.sub(EXTENSION_RE, '', string))\n",
    "        for string in strings:\n",
    "            self._precompute_pool[string] = (string,)\n",
    "        self._min_length = min([len(x) for x in self._precompute_pool.keys()])\n",
    "        initial_items = list(self._precompute_pool.items())\n",
    "        if precompute_hashes:\n",
    "            for string, name in initial_items:\n",
    "                self._compute_hashes(string, self._hash_layers, name)\n",
    "        if precompute_encodings:\n",
    "            for string, name in initial_items:\n",
    "                self._compute_encodings(string, self._encoding_layers, name)\n",
    "\n",
    "    def _split_on_delims(self, string, rv_parts, rv_named):\n",
    "        \"\"\"Splits a string on several delimiters\"\"\"\n",
    "        if string == '':\n",
    "            return\n",
    "        parts = set(re.split(DELIMITERS, string))\n",
    "        if '' in parts:\n",
    "            parts.remove('')\n",
    "        for part in parts:\n",
    "            if part == '':\n",
    "                continue\n",
    "            count = part.count('=')\n",
    "            if count != 1:\n",
    "                rv_parts.add(part)\n",
    "            if count == 0:\n",
    "                continue\n",
    "            n, k = part.split('=', 1)\n",
    "            if len(n) > 0 and len(k) > 0:\n",
    "                rv_named.add((n, k))\n",
    "            else:\n",
    "                rv_parts.add(part)\n",
    "\n",
    "    def check_if_in_precompute_pool(self, string):\n",
    "        \"\"\"Returns a tuple that lists the (possibly layered) hashes or\n",
    "        encodings that result in input string\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self._precompute_pool[str(string)]\n",
    "        except KeyError:\n",
    "            return\n",
    "        except (UnicodeDecodeError, UnicodeEncodeError):\n",
    "            return\n",
    "\n",
    "    def check_for_leak(self, string, layers=1, prev_encodings=tuple(),\n",
    "                       prev=''):\n",
    "        \"\"\"Check if given string contains a leak\"\"\"\n",
    "        # Short tokens won't contain email address\n",
    "        if len(string) < self._min_length:\n",
    "            return\n",
    "\n",
    "        # Check if direct hash or plaintext\n",
    "        rv = self.check_if_in_precompute_pool(string)\n",
    "        if rv is not None:\n",
    "            return prev_encodings + rv\n",
    "\n",
    "        # Try encodings\n",
    "        for encoding in self._encoding_set:\n",
    "            # multiple rots are unnecessary\n",
    "            if encoding.startswith('rot') and prev.startswith('rot'):\n",
    "                continue\n",
    "            try:\n",
    "                decoded = self._decoder.decode(encoding, string)\n",
    "                if type(decoded) == int:\n",
    "                    decoded = str(decoded)\n",
    "            except DecodeException:  # means this isn't the correct decoding\n",
    "                continue\n",
    "            if decoded == string:  # don't add no-ops\n",
    "                continue\n",
    "            if decoded is None:  # Empty decodings aren't useful\n",
    "                continue\n",
    "            encoding_stack = prev_encodings + (encoding,)\n",
    "            if layers > 1:\n",
    "                rv = self.check_for_leak(decoded, layers-1,\n",
    "                                         encoding_stack, encoding)\n",
    "                if rv is not None:\n",
    "                    return rv\n",
    "            else:\n",
    "                # New: allow substring matches\n",
    "                for known_string, transform_stack in self._precompute_pool.items():\n",
    "                    if known_string in str(decoded):\n",
    "                        return encoding_stack + transform_stack\n",
    "        return\n",
    "\n",
    "    def _check_parts_for_leaks(self, tokens, parameters, nlayers):\n",
    "        \"\"\"Check token and parameter string parts for leaks\"\"\"\n",
    "        leaks = list()\n",
    "        for token in tokens:\n",
    "            leak = self.check_for_leak(token, layers=nlayers)\n",
    "            if leak is not None:\n",
    "                leaks.append(leak)\n",
    "        for name, value in parameters:\n",
    "            leak = self.check_for_leak(value, layers=nlayers)\n",
    "            if leak is not None:\n",
    "                leaks.append(leak)\n",
    "            leak = self.check_for_leak(name, layers=nlayers)\n",
    "            if leak is not None:\n",
    "                leaks.append(leak)\n",
    "        return leaks\n",
    "\n",
    "    def _split_url(self, url):\n",
    "        \"\"\"Split url path and query string on delimiters\"\"\"\n",
    "        tokens = set()\n",
    "        parameters = set()\n",
    "        try:\n",
    "            purl = urlparse(url)\n",
    "        except ValueError:\n",
    "            print(f\"Can't parse url: {url}\")\n",
    "            return [], []\n",
    "        path_parts = purl.path.split('/')\n",
    "        for part in path_parts:\n",
    "            if not part.endswith('.com'):\n",
    "                part = re.sub(EXTENSION_RE, '', part)\n",
    "            self._split_on_delims(part, tokens, parameters)\n",
    "        self._split_on_delims(purl.query, tokens, parameters)\n",
    "        self._split_on_delims(purl.fragment, tokens, parameters)\n",
    "        return tokens, parameters\n",
    "\n",
    "    def check_url(self, url, encoding_layers=3, substring_search=True):\n",
    "        \"\"\"Check if a given url contains a leak\"\"\"\n",
    "        tokens, parameters = self._split_url(url)\n",
    "        if self._debugging:\n",
    "            print(\"URL tokens:\") \n",
    "            print(tokens)\n",
    "            for token in tokens:\n",
    "                print(token)\n",
    "            print(\"\\nURL parameters:\")\n",
    "            for key, value in parameters:\n",
    "                print(\"Key: %s | Value: %s\" % (key, value))\n",
    "        return self._check_whole_and_parts_for_leaks(\n",
    "            url, tokens, parameters, encoding_layers, substring_search)\n",
    "\n",
    "    def _get_header_str(self, header_str, header_name):\n",
    "        \"\"\"Returns the header string parsed from `header_str`\"\"\"\n",
    "        for item in json.loads(header_str):\n",
    "            if item[0] == header_name:\n",
    "                return item[1]\n",
    "        return \"\"\n",
    "\n",
    "    def _split_cookie(self, cookie_str, from_request=True):\n",
    "        \"\"\"Returns all parsed parts of the cookie names and values\"\"\"\n",
    "        tokens = set()\n",
    "        parameters = set()\n",
    "        try:\n",
    "            if from_request:\n",
    "                cookies = ck.Cookies.from_request(cookie_str)\n",
    "            else:\n",
    "                cookies = ck.Cookies.from_response(cookie_str,\n",
    "                                                   ignore_bad_cookies=True)\n",
    "        except (ck.InvalidCookieError, UnicodeDecodeError, KeyError):\n",
    "            return tokens, parameters  # return empty sets\n",
    "\n",
    "        for cookie in cookies.values():\n",
    "            self._split_on_delims(cookie.name, tokens, parameters)\n",
    "            self._split_on_delims(cookie.value, tokens, parameters)\n",
    "        return tokens, parameters\n",
    "\n",
    "    def get_location_str(self, header_str):\n",
    "        return self._get_header_str(header_str, \"Location\")\n",
    "\n",
    "    def get_referrer_str(self, header_str):\n",
    "        return self._get_header_str(header_str, \"Referer\")\n",
    "\n",
    "    def get_cookie_str(self, header_str, from_request=True):\n",
    "        if not header_str:\n",
    "            return \"\"\n",
    "        if from_request:\n",
    "            header_name = 'Cookie'\n",
    "        else:\n",
    "            header_name = 'Set-Cookie'\n",
    "\n",
    "        return self._get_header_str(header_str, header_name)\n",
    "\n",
    "    def check_cookies(self, header_str, encoding_layers=3,\n",
    "                      from_request=True, substring_search=True):\n",
    "        \"\"\"Check the cookies portion of the header string for leaks\"\"\"\n",
    "        cookie_str = self.get_cookie_str(header_str, from_request)\n",
    "        if not cookie_str:\n",
    "            return list()\n",
    "        tokens, parameters = self._split_cookie(header_str, from_request=from_request)\n",
    "        return self._check_whole_and_parts_for_leaks(\n",
    "            cookie_str, tokens, parameters, encoding_layers, substring_search)\n",
    "\n",
    "    def check_location_header(self, location_str, encoding_layers=3,\n",
    "                              substring_search=True):\n",
    "        \"\"\"Check the Location HTTP response header for leaks.\"\"\"\n",
    "        if location_str == '':\n",
    "            return list()\n",
    "        tokens, parameters = self._split_url(location_str)\n",
    "        return self._check_whole_and_parts_for_leaks(\n",
    "            location_str, tokens, parameters, encoding_layers,\n",
    "            substring_search)\n",
    "\n",
    "    def check_referrer_header(self, header_str, encoding_layers=3,\n",
    "                              substring_search=True):\n",
    "        \"\"\"Check the Referer HTTP request header for leaks.\"\"\"\n",
    "        if header_str == '':\n",
    "            return list()\n",
    "        referrer_str = self.get_referrer_str(header_str)\n",
    "        # We use this check instead of ==''\n",
    "        # since _get_header_str may return None\n",
    "        if not referrer_str:\n",
    "            return list()\n",
    "        tokens, parameters = self._split_url(referrer_str)\n",
    "        return self._check_whole_and_parts_for_leaks(\n",
    "            referrer_str, tokens, parameters, encoding_layers,\n",
    "            substring_search)\n",
    "    \n",
    "\n",
    "    def _extract_url_style_payload(self, payload_str, tokens, parameters, seen, depth):\n",
    "            \"\"\"\n",
    "            Extract tokens and named parameters from a URL-style payload.\n",
    "            Example: en=Scroll_depth&epn.scroll_depth=30&ep.url=https%3A%2F%2Fexample.com\n",
    "            \"\"\"\n",
    "            if depth > 3 or payload_str in seen:\n",
    "                return\n",
    "            seen.add(payload_str)\n",
    "\n",
    "            try:\n",
    "                pairs = payload_str.split('&')\n",
    "                for pair in pairs:\n",
    "                    if '=' in pair:\n",
    "                        k, v = pair.split('=', 1)\n",
    "                        k = k.strip()\n",
    "                        v = unquote_plus(v.strip())\n",
    "                        tokens.add(k)\n",
    "                        tokens.add(v)\n",
    "                        parameters.add((k, v))\n",
    "\n",
    "                        # Recursively extract deeper from values\n",
    "                        self._split_on_delims(k, tokens, parameters)\n",
    "                        self._split_on_delims(v, tokens, parameters)\n",
    "\n",
    "                        # Recurse into value for deeper encoding\n",
    "                        for enc in LIKELY_ENCODINGS:\n",
    "                            try:\n",
    "                                decoded = self._decoder.decode(enc, v)\n",
    "                                if isinstance(decoded, bytes):\n",
    "                                    decoded = decoded.decode(\"utf-8\", errors=\"ignore\")\n",
    "                                decoded = decoded.strip()\n",
    "                                if decoded and decoded != v:\n",
    "                                    self._extract_url_style_payload(decoded, tokens, parameters, seen, depth + 1)\n",
    "                            except Exception:\n",
    "                                continue\n",
    "                    else:\n",
    "                        tokens.add(pair)\n",
    "            except Exception as e:\n",
    "                if self._debugging:\n",
    "                    print(f\"Error parsing URL-style payload: {e}\")\n",
    "           \n",
    "    def _extract_json_array_payload(self, payload_str, tokens, parameters, seen, depth):\n",
    "        \"\"\"\n",
    "        Extract tokens and values from a JSON array-style payload.\n",
    "        Handles deeply nested arrays.\n",
    "        \"\"\"\n",
    "        if depth > 3 or payload_str in seen:\n",
    "            return\n",
    "        seen.add(payload_str)\n",
    "\n",
    "        try:\n",
    "            data = json.loads(payload_str)\n",
    "            if not isinstance(data, list):\n",
    "                return\n",
    "\n",
    "            def recurse_array(arr, depth):\n",
    "                if depth > 3:\n",
    "                    return\n",
    "                for item in arr:\n",
    "                    if isinstance(item, list):\n",
    "                        recurse_array(item, depth + 1)\n",
    "                    elif isinstance(item, dict):\n",
    "                        for k, v in item.items():\n",
    "                            k = str(k).strip()\n",
    "                            v = str(v).strip()\n",
    "                            tokens.add(k)\n",
    "                            tokens.add(v)\n",
    "                            parameters.add((k, v))\n",
    "                            self._split_on_delims(k, tokens, parameters)\n",
    "                            self._split_on_delims(v, tokens, parameters)\n",
    "                    elif item is not None:\n",
    "                        val = str(item).strip()\n",
    "                        tokens.add(val)\n",
    "                        self._split_on_delims(val, tokens, parameters)\n",
    "\n",
    "            recurse_array(data, 0)\n",
    "\n",
    "        except Exception as e:\n",
    "            if self._debugging:\n",
    "                print(f\"Error parsing JSON array payload: {e}\")\n",
    "    def _extract_json_object_payload(self, payload_str, tokens, parameters, seen, depth):\n",
    "        \"\"\"\n",
    "        Extract tokens and key-value pairs from a JSON object-style payload.\n",
    "        Handles deeply nested dictionaries.\n",
    "        \"\"\"\n",
    "        if depth > 3 or payload_str in seen:\n",
    "            return\n",
    "        seen.add(payload_str)\n",
    "\n",
    "        try:\n",
    "            data = json.loads(payload_str)\n",
    "            if not isinstance(data, dict):\n",
    "                return\n",
    "\n",
    "            def recurse_obj(obj, depth):\n",
    "                if depth > 3:\n",
    "                    return\n",
    "                for k, v in obj.items():\n",
    "                    k_str = str(k).strip()\n",
    "                    tokens.add(k_str)\n",
    "\n",
    "                    if isinstance(v, dict):\n",
    "                        recurse_obj(v, depth + 1)\n",
    "                    elif isinstance(v, list):\n",
    "                        for item in v:\n",
    "                            if isinstance(item, (dict, list)):\n",
    "                                recurse_obj(item, depth + 1)\n",
    "                            else:\n",
    "                                val = str(item).strip()\n",
    "                                tokens.add(val)\n",
    "                                parameters.add((k_str, val))\n",
    "                                self._split_on_delims(val, tokens, parameters)\n",
    "                    elif v is not None:\n",
    "                        val = str(v).strip()\n",
    "                        tokens.add(val)\n",
    "                        parameters.add((k_str, val))\n",
    "                        self._split_on_delims(k_str, tokens, parameters)\n",
    "                        self._split_on_delims(val, tokens, parameters)\n",
    "\n",
    "            recurse_obj(data, 0)\n",
    "\n",
    "        except Exception as e:\n",
    "            if self._debugging:\n",
    "                print(f\"Error parsing JSON object payload: {e}\")\n",
    "                \n",
    "    def check_payload(self, payload_str, encoding_layers=3, substring_search=True):\n",
    "        tokens = set()\n",
    "        parameters = set()\n",
    "        seen_payloads = set()\n",
    "        \n",
    "        \n",
    "\n",
    "      #  self._extract_url_style_payload(payload_str, tokens, parameters, seen_payloads, depth=0)\n",
    "       # self._extract_json_array_payload(payload_str, tokens, parameters, seen_payloads, depth=0)\n",
    "       # self._extract_json_object_payload(payload_str, tokens, parameters, seen_payloads, depth=0)\n",
    "\n",
    "        if self._debugging:\n",
    "            print(\"Tokens:\", tokens)\n",
    "            print(\"Parameters:\", parameters)\n",
    "\n",
    "        return self._check_whole_and_parts_for_leaks(\n",
    "            payload_str, tokens, parameters, encoding_layers, substring_search\n",
    "        )\n",
    "           \n",
    "    def _check_whole_and_parts_for_leaks(self, input_string, tokens,\n",
    "                                         parameters, encoding_layers,\n",
    "                                         substring_search):\n",
    "        \"\"\"Search an input string and its parts for leaks.\"\"\"\n",
    "        results = self._check_parts_for_leaks(tokens, parameters,\n",
    "                                              encoding_layers)\n",
    "        if substring_search:\n",
    "            substr_results = self.substring_search(input_string, max_layers=2)\n",
    "            # filter repeating results\n",
    "            return list(set(results + substr_results))\n",
    "        else:\n",
    "            return results\n",
    "\n",
    "    def substring_search(self, input_string, max_layers=None):\n",
    "        \"\"\"Do a substring search for all precomputed hashes/encodings\n",
    "\n",
    "        `max_layers` limits the number of encoding/hashing layers used in the\n",
    "        substring search (to limit time). The default is no limit (`None`).\n",
    "        \"\"\"\n",
    "        if input_string is None or input_string == '':\n",
    "            return list()\n",
    "        try:\n",
    "            input_string = input_string.encode('utf8')\n",
    "        except (UnicodeDecodeError, UnicodeEncodeError):\n",
    "            print(f\"ERROR encoding: {repr(input_string)}\")\n",
    "            return list()\n",
    "        leaks = list()\n",
    "        for string, transform_stack in self._precompute_pool.items():\n",
    "            if max_layers and len(transform_stack) > (max_layers + 1):\n",
    "                continue\n",
    "            if string.encode('utf-8', errors='ignore') in input_string:\n",
    "                leaks.append(transform_stack)\n",
    "        return leaks\n",
    "    \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample value to detect\n",
    "    secret = \"hi_my\"\n",
    "\n",
    "    # Create the leak detector with one known secret string\n",
    "    detector = LeakDetector(search_strings=[secret], debugging=True)\n",
    "\n",
    "    # Example URL containing a base64-encoded version of the secret\n",
    "    import base64\n",
    "    encoded_secret = base64.b64encode(secret.encode()).decode()\n",
    "    url = f\"https://example.com/profile?token={encoded_secret}&id=123\"\n",
    "    payload= \"\"\"\n",
    "    {\\\"body\\\":\\\"eJyVjssKwjAQRf/lrmcRlTZNfiUMJbSRlrS6EAtB+u9OgmjFjV3N484ZjnO1UpUhxB70wNjDmoYww579dAvSRVjHksMigNB1sEpGKbVZmTKvT4SCe9m6zxcvzOKne+YW6YexnVM7XC8BK2/YCMrnm7hkWlX/eaVvr+blpY+HvV7pLVbgH7EE5ic+HlWr\\\",\\\"chunk_number\\\":0,\\\"encoding\\\":\\\"zlib64\\\",\\\"request_number\\\":11,\\\"token\\\":\\\"7KSx1snskTybS6xlHnYNsAfzTHCFoGrMrYtsdcVj/Y3duTy4/64J/4IBCpc1YUAhFbgfC8BZJpZEQ8hD/a/na+/K+BmA8RLjZYPwNB2m\\\"}\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Checking URL ===\")\n",
    "    leaks = detector.check_url(url)\n",
    "    leaks_payload = detector.check_payload(payload)\n",
    "    print(\"Leaks found in URL:\", leaks)\n",
    "    \n",
    "    print(\"Leaks found in Payload:\", leaks_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb877f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base16': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'base32': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'base58': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'base64': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'urlencode': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'deflate': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'zlib': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'gzip': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'json': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'binary': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'entity': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'rot13': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'rot1': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=1)>,\n",
       " 'rot2': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=2)>,\n",
       " 'rot3': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=3)>,\n",
       " 'rot4': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=4)>,\n",
       " 'rot5': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=5)>,\n",
       " 'rot6': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=6)>,\n",
       " 'rot7': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=7)>,\n",
       " 'rot8': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=8)>,\n",
       " 'rot9': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=9)>,\n",
       " 'rot10': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=10)>,\n",
       " 'rot11': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=11)>,\n",
       " 'rot12': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=12)>,\n",
       " 'rot14': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=14)>,\n",
       " 'rot15': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=15)>,\n",
       " 'rot16': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=16)>,\n",
       " 'rot17': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=17)>,\n",
       " 'rot18': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=18)>,\n",
       " 'rot19': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=19)>,\n",
       " 'rot20': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=20)>,\n",
       " 'rot21': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=21)>,\n",
       " 'rot22': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=22)>,\n",
       " 'rot23': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=23)>,\n",
       " 'rot24': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=24)>,\n",
       " 'rot25': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x, i=25)>,\n",
       " 'lz64': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'zlib64': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'lz64de': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'lz_string': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'brotli_base64': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'deflate_base64': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'deflateraw_base64': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'gzip_base64': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'deflate_hex': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>,\n",
       " 'gzip_hex': <function __main__.decode_or_decompress_tokens.<locals>.<lambda>(x)>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "decodings = dict()\n",
    "decodings['base16'] = lambda x: base64.b16decode(x)\n",
    "decodings['base32'] = lambda x: base64.b32decode(x)\n",
    "decodings['base58'] = lambda x: base58.b58decode(x)\n",
    "decodings['base64'] = lambda x: base64.b64decode(x)\n",
    "decodings['urlencode'] = lambda x: unquote_plus(x)\n",
    "decodings['deflate'] = lambda x: _decompress_with_zlib('deflate',\n",
    "                                                            x)\n",
    "decodings['zlib'] = lambda x: _decompress_with_zlib('zlib', x)\n",
    "decodings['gzip'] = lambda x: _decompress_with_zlib('gzip', x)\n",
    "decodings['json'] = lambda x: json.loads(x)\n",
    "decodings['binary'] = lambda x: ''.join(chr(int(x[i:i+8], 2)) for i in range(0, len(x), 8))\n",
    "decodings['entity'] = lambda x: html.unescape(x)\n",
    "\n",
    "decodings['rot13'] = lambda x: codecs.decode(x, 'rot_13')\n",
    "\n",
    "for i in range(1, 26):\n",
    "    if i == 13:\n",
    "        continue  # handled separately with codecs\n",
    "    decodings[f'rot{i}'] = lambda x, i=i: rot_n(x, i)\n",
    "    \n",
    "try:\n",
    "    lz = LZString()\n",
    "    decodings['lz64'] = lambda x: lz.decompress(base64.b64decode(x).decode('utf-8'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "decodings['zlib64'] = lambda x: zlib.decompress(base64.b64decode(x)).decode('utf-8', errors='ignore')\n",
    "\n",
    "try:\n",
    "    lz = LZString()\n",
    "    decodings['lz64de'] = lambda x: LZString().decompress(base64.b64decode(x).decode('utf-8'))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    lz = LZString()\n",
    "    decodings['lz_string'] = lambda x: lz.decompressFromEncodedURIComponent(x)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try: \n",
    "    import lzw\n",
    "    decodings['lzw'] = lambda x: ''.join(lzw.decode(json.loads(x)))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    decodings['brotli_base64'] = lambda x: brotli.decompress(base64.b64decode(x)).decode('utf-8', errors='ignore')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "decodings['deflate_base64'] = lambda x: zlib.decompress(base64.b64decode(x), -zlib.MAX_WBITS).decode('utf-8', errors='ignore')\n",
    "decodings['deflateraw_base64'] = lambda x: zlib.decompress(base64.b64decode(x), -zlib.MAX_WBITS).decode('utf-8', errors='ignore')\n",
    "decodings['gzip_base64'] = lambda x: zlib.decompress(base64.b64decode(x), zlib.MAX_WBITS | 16).decode('utf-8', errors='ignore')\n",
    "decodings['deflate_hex'] = lambda x: zlib.decompress(bytes.fromhex(x)).decode('utf-8', errors='ignore')\n",
    "decodings['gzip_hex'] = lambda x: zlib.decompress(bytes.fromhex(x), zlib.MAX_WBITS | 16).decode('utf-8', errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16838f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded text:\n",
      " [[64821,\"kd\",{\"id\":98,\"m\":false,\"mk\":[],\"k\":\"x\",\"cc\":0,\"kc\":88}],[64832,\"d\",{\"ac\":[{\"id\":98,\"a\":\"value\",\"v\":\"hi_my_honey_tex\"}]}],[64832,\"k\",98,\"hi_my_honey_tex\"]]\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import zlib\n",
    "\n",
    "def decode_zlib64(encoded_str):\n",
    "    try:\n",
    "        compressed_data = base64.b64decode(encoded_str)\n",
    "        decompressed_data = zlib.decompress(compressed_data)\n",
    "        return decompressed_data.decode('utf-8', errors='replace')  # Replace undecodable chars\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR] {e}\"\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    zlib64_text = \"eJxdjEsOhDAMQ+/idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v+TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4=\"  # Example input\n",
    "    decoded = decode_zlib64(zlib64_text)\n",
    "    print(\"Decoded text:\\n\", decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02a9375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "------\n",
      "------\n",
      "------\n",
      "*********\n",
      "*********\n",
      "*********\n",
      "Checking value: 34393232313232323030\n",
      "Checking value: GQ4TEMRRGIZDEMBQ\n",
      "Checking value: 3wAzuvCkRADzGP\n",
      "Checking value: NDkyMjEyMjIwMA==\n",
      "Checking value: 4922122200\n",
      "Checking value: 33b134323234323232300000\n",
      "Checking value: 789c33b1343232343232323000000b0f01f9\n",
      "Checking value: 1f8b080000000000001333b134323234323232300000a3e481680a000000\n",
      "Checking value: 00110100001110010011001000110010001100010011001000110010001100100011000000110000\n",
      "Checking value: 4922122200\n",
      "Checking value: 4922122200\n",
      "Checking value: M7E0MjI0MjIyMAAA\n",
      "Checking value: M7E0MjI0MjIyMAAA\n",
      "Checking value: H4sIAAAAAAAAEzOxNDIyNDIyMjAAAKPkgWgKAAAA\n",
      "Checking value: iwSANDkyMjEyMjIwMAM=\n",
      "Checking value: 33b134323234323232300000\n",
      "Checking value: 1f8b080000000000001333b134323234323232300000a3e481680a000000\n",
      "Checking value: eJwzsTQyMjQyMjIwAAALDwH5\n",
      "Checking value: 4KyE7oGM5oKM4ZiA7K2A\n",
      "Checking value: 4KyE7oGM5oKM4ZiA7K2A\n",
      "Checking value: CwTgTGCMFgDLQ\n",
      "Checking value: 84d3a0756276940932da44e047086405\n",
      "Checking value: 7391027a4dcdd6dfa459dfe85e9cd208f7e70ca7\n",
      "Checking value: e2ddeff7f6379160d21bf08d333a18c7b0a290c974f6451903bfc7d301b7df04\n",
      "Checking value: d8f3d7fe7d03fdacc24d4dfca1bba976cf88450b325d25f93c10ba0f\n",
      "Checking value: 208aa443dc30af0140762b17e1f268b628fbc7a18515e68104e22eefe9a9a0e5b8e7e07a6a6b073991e66e7bc49c978d\n",
      "Checking value: e1bf1080654ed05dd2a9c0ad2a2b61113febe705d0981fe82a6d3ff0b4c6fbfde33e8a3d5ec73341f233578d3e75a4a4394a6b3290628b9e684e0719b76f323d\n",
      "Checking value: 009700fd326c4896ad286fa000671376eacb78ddddc01c58a4381671\n",
      "Checking value: ffbc43328e658b91b896e1a3dc5218c9549357643504cbe1ebcbe7ea0e865247\n",
      "Checking value: 69e26e31d0e4489c1717f7cc215ff3824dd359f2dc9b1cf445962a704cf5c511c878ade2887db1d39bbf5f8094b42f4e\n",
      "Checking value: af33a8963c06306fab91e1466c8eb3da039b7149d351db1db55da38dd4f132c26597161fd0bddf002c430642357c31d92e1981f9775cf8f7acde08c1abe22e28\n",
      "Checking value: 2022247329\n",
      "Checking value: -2687720209116599037\n",
      "Checking value: 3451519139391771119\n",
      "Checking value: 63669290229870245713155212006181530883\n",
      "Checking value: 1753343139\n",
      "Checking value: 185532921\n",
      "Checking value: 53616C747953656564735465613921\n",
      "Checking value: KNQWY5DZKNSWKZDTKRSWCOJB\n",
      "Checking value: 3LJJbd4hWsNsevDznEiiU\n",
      "Checking value: U2FsdHlTZWVkc1RlYTkh\n",
      "Checking value: SaltySeedsTea9%21\n",
      "Checking value: 0b4ecc29a90c4e4d4d290e494db4540400\n",
      "Checking value: 789c0b4ecc29a90c4e4d4d290e494db45404002ea80576\n",
      "Checking value: 1f8b08000000000000130b4ecc29a90c4e4d4d290e494db454040084448f8b0f000000\n",
      "Checking value: 010100110110000101101100011101000111100101010011011001010110010101100100011100110101010001100101011000010011100100100001\n",
      "Checking value: SaltySeedsTea9!\n",
      "Checking value: FnyglFrrqfGrn9!\n",
      "Checking value: C07MKakMTk1NKQ5JTbRUBAA=\n",
      "Checking value: C07MKakMTk1NKQ5JTbRUBAA=\n",
      "Checking value: H4sIAAAAAAAAEwtOzCmpDE5NTSkOSU20VAQAhESPiw8AAAA=\n",
      "Checking value: CweAU2FsdHlTZWVkc1RlYTkhAw==\n",
      "Checking value: 0b4ecc29a90c4e4d4d290e494db4540400\n",
      "Checking value: 1f8b08000000000000130b4ecc29a90c4e4d4d290e494db454040084448f8b0f000000\n",
      "Checking value: eJwLTswpqQxOTU0pDklNtFQEAC6oBXY=\n",
      "Checking value: 44qE44C2y6Dpu4DqmrDhjIPjoIXlmKDinIHgooA=\n",
      "Checking value: 44qE44C2y6Dpu4DqmrDhjIPjoIXlmKDinIHgooA=\n",
      "Checking value: MoQwNgLgnsCmsBMDOAVWICcBCIA\n",
      "Checking value: 4948c713c8f51fcdf341fe5dc5f7f651\n",
      "Checking value: 486566dce40fe64622d123079598b9a0bef88551\n",
      "Checking value: 2f50045ec0f7fd7ef014aff67338010772fa21226c0b1ca4bb8a596b85a2110f\n",
      "Checking value: 2f842ab50309d0bc9db92b5921e71423cc438172313b9e3739669e06\n",
      "Checking value: cb972f03b4d1e1032aecbc095904fd3ce72e0082498eec3fa92b5fa928ca14be586f7838b71c6c7ecde2aedaa2cfe3dc\n",
      "Checking value: d1767a28de17b8862d8d0aebe238048082fa4d43292c941d9e45fee739beea1910d9e528174b0b4597ff9b3b9d0f59eaae00646bb25e74436836b47885bec58c\n",
      "Checking value: 12eb75e22875ddf3f4f9df97b55fcdc694a3602ce38b48c03bd709f0\n",
      "Checking value: 254b968eda5a4c4ec77b44c5f0c18486b7dcae428586446cc7e32bc4b44efd58\n",
      "Checking value: 7f2ea3fbaa3a4655eb902c84e430c2328e98655bb2eba58235067736d62137d923df8578d7dff74439ff42afd8d44ff3\n",
      "Checking value: 57ddbf73386b32c4a923a3268ec4837db4e52f84a3eca0b4e2aa6ea1dd87015fe873aa048cb84bf3f3c6790cd1f5dcfadbf67148bbe05f2664f5f6c71702dbdf\n",
      "Checking value: -287875941\n",
      "Checking value: 2630329490964472104\n",
      "Checking value: 5021836792884838330\n",
      "Checking value: 92636538098284972449800741919914713384\n",
      "Checking value: 2341422212\n",
      "Checking value: 782763382\n",
      "Checking value: 68695F6D795F686F6E65795F74657874\n",
      "Checking value: NBUV63LZL5UG63TFPFPXIZLYOQ======\n",
      "Checking value: DtohHfG9wm5HUTLmENZzeX\n",
      "Checking value: aGlfbXlfaG9uZXlfdGV4dA==\n",
      "Checking value: hi_my_honehi_my_honey_text\n",
      "Checking value: cbc88ccfad8ccfc8cf4bad8c2f49ad280100\n",
      "Checking value: 789ccbc88ccfad8ccfc8cf4bad8c2f49ad280100387106bd\n",
      "Checking value: 1f8b0800000000000013cbc88ccfad8ccfc8cf4bad8c2f49ad2801002ffbe42910000000\n",
      "Checking value: 01101000011010010101111101101101011110010101111101101000011011110110111001100101011110010101111101110100011001010111100001110100\n",
      "Checking value: hi_my_honey_text\n",
      "Checking value: uv_zl_ubarl_grkg\n",
      "Checking value: y8iMz62Mz8jPS62ML0mtKAEA\n",
      "Checking value: y8iMz62Mz8jPS62ML0mtKAEA\n",
      "Checking value: H4sIAAAAAAAAE8vIjM+tjM/Iz0utjC9JrSgBAC/75CkQAAAA\n",
      "Checking value: iweAaGlfbXlfaG9uZXlfdGV4dAM=\n",
      "Checking value: cbc88ccfad8ccfc8cf4bad8c2f49ad280100\n",
      "Checking value: 1f8b0800000000000013cbc88ccfad8ccfc8cf4bad8c2f49ad2801002ffbe42910000000\n",
      "Checking value: eJzLyIzPrYzPyM9LrYwvSa0oAQA4cQa9\n",
      "Checking value: 1oTrg7rgraDpuazgvaDjrILpo4DiuYjequiAgA==\n",
      "Checking value: 1oTrg7rgraDpuazgvaDjrILpo4DiuYjequiAgA==\n",
      "Checking value: BYSw+gtgnmwPYDsCmMAuSAeqg\n",
      "Checking value: 43e75bec2b6f2c204cb19a21baf28e34\n",
      "Checking value: eea0bb214e955ddb5eef9c486af767e8fbc5cb39\n",
      "Checking value: 1ca570fac198727f82d0010004584b693c6e79b65c923acef84bf4169912ea33\n",
      "Checking value: f6823a0e876191719d95ab3023ee076757ad447377d93b47abf36b90\n",
      "Checking value: 44ae82b98381ea880d1135c8ffdd52da3764fe1f1bfb693767ed25c4f6fbab8f04f675e43e5adcaa9b2bcdd07ffcda61\n",
      "Checking value: 013c9434fcc85dc02d8d50a38fc2f6495173e053b6d57b8071bd35115ff79ef8a03132d77e7e47ef0fc1e7e9873e3ae27c6b64972362751ef01b3443ad7481b3\n",
      "Checking value: 80ad41185430a92c32308e71f8d07ed84c6285a05492946e7bc3168d\n",
      "Checking value: 047ba5082a889660c46380e777a8ba2ee4e0dd4bbca69a270e67585454125b46\n",
      "Checking value: f55210fbf2e577b3bc36bc961b960fa3963a7be7878309c847f46f0d7cc4d7b968fe0cf18ecc12b54d4fb7680c56c66a\n",
      "Checking value: 2c752ade168750df0fb478e5f8eb9fb821af98d367aee0f916402622a7bc343df8840de8a54a5d505ee96d516451ca6949ad37f0a18ad2b9c93057254e3ee0ef\n",
      "Checking value: 1753757807\n",
      "Checking value: -2047910037623045259\n",
      "Checking value: 3847981994889785074\n",
      "Checking value: 70982739059974200961265151179235885941\n",
      "Checking value: 702872367\n",
      "Checking value: 946931389\n",
      "Checking value: 68695F6D795F686F6E65795F6669656C64\n",
      "Checking value: NBUV63LZL5UG63TFPFPWM2LFNRSA====\n",
      "Checking value: yuf6pXstUhXuiBGECSh1Nzf\n",
      "Checking value: aGlfbXlfaG9uZXlfZmllbGQ=\n",
      "Checking value: hi_my_honey_field\n",
      "Checking value: cbc88ccfad8ccfc8cf4bad8c4fcb4ccd490100\n",
      "Checking value: 789ccbc88ccfad8ccfc8cf4bad8c4fcb4ccd4901003f1306fc\n",
      "Checking value: 1f8b0800000000000013cbc88ccfad8ccfc8cf4bad8c4fcb4ccd4901004e4036f511000000\n",
      "Checking value: 0110100001101001010111110110110101111001010111110110100001101111011011100110010101111001010111110110011001101001011001010110110001100100\n",
      "Checking value: hi_my_honey_field\n",
      "Checking value: uv_zl_ubarl_svryq\n",
      "Checking value: y8iMz62Mz8jPS62MT8tMzUkBAA==\n",
      "Checking value: y8iMz62Mz8jPS62MT8tMzUkBAA==\n",
      "Checking value: H4sIAAAAAAAAE8vIjM+tjM/Iz0utjE/LTM1JAQBOQDb1EQAAAA==\n",
      "Checking value: CwiAaGlfbXlfaG9uZXlfZmllbGQD\n",
      "Checking value: cbc88ccfad8ccfc8cf4bad8c4fcb4ccd490100\n",
      "Checking value: 1f8b0800000000000013cbc88ccfad8ccfc8cf4bad8c4fcb4ccd4901004e4036f511000000\n",
      "Checking value: eJzLyIzPrYzPyM9LrYxPy0zNSQEAPxMG/A==\n",
      "Checking value: 1oTrg7rgraDpuazgvaDjrILpo4DmmKLkgazJpAA=\n",
      "Checking value: 1oTrg7rgraDpuazgvaDjrILpo4DmmKLkgazJpAA=\n",
      "Checking value: BYSw+gtgnmwPYDsCmMBmIkBsAmQ\n",
      "Checking value: f505c12230d40a5dd2538d83eedd7da7\n",
      "Checking value: 5291e16b1c4f5afef57fb6987b0c838295871e02\n",
      "Checking value: 1643c39ff8767f67ee17e7eaf7cb19ce976af8a0b9d3ecc4218111217e372f7d\n",
      "Checking value: b78094ae62a41967e4aa69fd21bee354119d2c56ab68eaffdf197c1c\n",
      "Checking value: 3889e1e25d2983e3633edbed592734719c1c6430ec3203aceac3a487129135d20bb2ae1dcd2be66b1fbec52a1c633350\n",
      "Checking value: 8b180d4b7d90628533162567bbe3418b2f5520ee7a9de275dd3a0138cf14a7e1893bc8b525bf03772c7328d73e6972686b056b21f2bb03ca2f45c5096b2c9f83\n",
      "Checking value: 3a0c7071c21fe32fdb512689ef2e4b16b6ee7f04db7a3df039e49d4b\n",
      "Checking value: de96f137b568833a6f68a4d358ec56bf28e3b1d1d42916a1a0f8afe690c54afe\n",
      "Checking value: 86126692cbbf6c0341274afc4c5d98afeca05a7330ef8748d491e87a2df4ae39f01128c6f349f9dccc62e1cd91bd50a9\n",
      "Checking value: 23f5e7432d6def6b1517a051f35332f199ea95fae1456242909ca845e977dee52e55110f12ee1ed16cbd139ac0332a7e3e1d0cb60d008e523598e76fa4440cc7\n",
      "Checking value: 1248393586\n",
      "Checking value: -6414144220524007930\n",
      "Checking value: -3909599843592213748\n",
      "Checking value: 268162979175578004603604889171042938374\n",
      "Checking value: 4113973326\n",
      "Checking value: 1058211580\n",
      "Checking value: 637572696F75732D6361742E636F6D\n",
      "Checking value: MN2XE2LPOVZS2Y3BOQXGG33N\n",
      "Checking value: 3nPVd4R2N6xz4UUk2Zzhi\n",
      "Checking value: Y3VyaW91cy1jYXQuY29t\n",
      "Checking value: curious-cat.com\n",
      "Checking value: 4b2e2dcacc2f2dd64d4e2cd14bcecf0500\n",
      "Checking value: 789c4b2e2dcacc2f2dd64d4e2cd14bcecf0500302d05dd\n",
      "Checking value: 1f8b08000000000000134b2e2dcacc2f2dd64d4e2cd14bcecf0500c7c1a0530f000000\n",
      "Checking value: 011000110111010101110010011010010110111101110101011100110010110101100011011000010111010000101110011000110110111101101101\n",
      "Checking value: curious-cat.com\n",
      "Checking value: phevbhf-png.pbz\n",
      "Checking value: Sy4tyswvLdZNTizRS87PBQA=\n",
      "Checking value: Sy4tyswvLdZNTizRS87PBQA=\n",
      "Checking value: H4sIAAAAAAAAE0suLcrMLy3WTU4s0UvOzwUAx8GgUw8AAAA=\n",
      "Checking value: CweAY3VyaW91cy1jYXQuY29tAw==\n",
      "Checking value: 4b2e2dcacc2f2dd64d4e2cd14bcecf0500\n",
      "Checking value: 1f8b08000000000000134b2e2dcacc2f2dd64d4e2cd14bcecf0500c7c1a0530f000000\n",
      "Checking value: eJxLLi3KzC8t1k1OLNFLzs8FADAtBd0=\n",
      "Checking value: 44aF54GO4KWg75ig7LiL5LCC4aCF7IG07IqB5rKA\n",
      "Checking value: 44aF54GO4KWg75ig7LiL5LCC4aCF7IG07IqB5rKA\n",
      "Checking value: MYVwTglg9iDOC0wCGAXAdMKBbIA\n",
      "Checking value: caf5110f98f91040e84a02862066fa65\n",
      "Checking value: b7027c2cda316afe9530e01130788e901fcb7913\n",
      "Checking value: 2d216e6c59d921ffeba58dfff2b8581666172fd57bf6ee6e44ad224cb4b45a78\n",
      "Checking value: 897f1d1072385b8da1f8f3ca466d346be023f8eb335192fce69cea70\n",
      "Checking value: a50db105ebf563ca079ecfd786f943a0e0e392b762a387ad129bc3fff3b468cc15e2ededf353c681456551eaa3bd6137\n",
      "Checking value: 9a8b60802fe42fb6aae650c391181b1e54c3a0f8efd1a180b4d698f0a6cdeceeb694c0f740cffbf49c75f0634c18283fff3c3380e5710774616b39a68a8c9bbb\n",
      "Checking value: ef2d53be51971fb181b05ac122cd1f67407624fe9b22fd3d062d21b4\n",
      "Checking value: 0915e1bf120f2dc9d303b2a2e7a19938bfa1a78921238eb1776d2fbacd25cb5a\n",
      "Checking value: 2def97b3ff239ce0096eaa28aa320fa717f2381c7000c46cec7e0fcae6d3f475ea712b5a6b8b5915665b0d82231a5b6c\n",
      "Checking value: cf9b6c7ac1c7f44f3eda22592edd8094e97e5d04b00f830365d024be8ad3f15c559194d8ec5bad598e567b562698ec4fe5a9a363363450b4ed2419564c1be4b8\n",
      "Checking value: -679406168\n",
      "Checking value: 2755373884543779069\n",
      "Checking value: -3309345380778307472\n",
      "Checking value: 279235719630208140617208984455809515773\n",
      "Checking value: 1403044295\n",
      "Checking value: 808256989\n",
      "Checking value: 68747470733A2F2F637572696F75732D6361742E636F6D\n",
      "Checking value: NB2HI4DTHIXS6Y3VOJUW65LTFVRWC5BOMNXW2===\n",
      "Checking value: 3A8evQZovd7B4jbwRyktga3ZR6388nYC\n",
      "Checking value: aHR0cHM6Ly9jdXJpb3VzLWNhdC5jb20=\n",
      "Checking value: https%3A%2F%2Fcurious-cat.com\n",
      "Checking value: cb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500\n",
      "Checking value: 789ccb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500687508a8\n",
      "Checking value: 1f8b0800000000000013cb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500b9e6387817000000\n",
      "Checking value: 0110100001110100011101000111000001110011001110100010111100101111011000110111010101110010011010010110111101110101011100110010110101100011011000010111010000101110011000110110111101101101\n",
      "Checking value: https://curious-cat.com\n",
      "Checking value: uggcf://phevbhf-png.pbz\n",
      "Checking value: yygpKSi20tdPLi3KzC8t1k1OLNFLzs8FAA==\n",
      "Checking value: yygpKSi20tdPLi3KzC8t1k1OLNFLzs8FAA==\n",
      "Checking value: H4sIAAAAAAAAE8soKSkottLXTy4tyswvLdZNTizRS87PBQC55jh4FwAAAA==\n",
      "Checking value: GxYA+MVTFpMaTJJsfhWMQGWKSyTptDo7iE8=\n",
      "Checking value: cb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500\n",
      "Checking value: 1f8b0800000000000013cb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500b9e6387817000000\n",
      "Checking value: eJzLKCkpKLbS108uLcrMLy3WTU4s0UvOzwUAaHUIqA==\n",
      "Checking value: 1oHnhIHshpzgroHupaDsmIXngJPohKzgvaTsoJbohITjhIDjqITjgJbsoIA=\n",
      "Checking value: 1oHnhIHshpzgroHupaDsmIXngJPohKzgvaTsoJbohITjhIDjqITjgJbsoIA=\n",
      "Checking value: BYFxAcGcC4HpYMYFcBOBLA9kyBaBBDEAOgQwFsg\n",
      "Checking value: c1a8de3f62604990390ff0555a524865\n",
      "Checking value: 41982bd1605b895577c73fe915e0d341c880fb60\n",
      "Checking value: c9b19caac3fa71da9addc8270a4769744ea11f2a6a5edc27ebc1c532951cc291\n",
      "Checking value: ed944b6e4b7a5d8d3124a20099f6126f46d398f793b9623229c108e1\n",
      "Checking value: 945e4b8f11d001863cc3ad23d239d8405484b673ba7e5f3039c7d55b32e20a72634b478f9a69f9c30beac7becf86ad8e\n",
      "Checking value: 938ca936fd2bcdff508bbea2c5665c2d4f618129c41a9fa88ad40917b9402150ee4836d26b1946d357476e0d2c7e1cad32b792faa45740474e0e7cafd94d8ffb\n",
      "Checking value: 6c901274c1162a4c9bd9a8580e06b6c2d3e4724ee62bfe89954b81cc\n",
      "Checking value: c1d03e01aaa3442521f7d9d45fbbc02e38ce550103ac44303f511ffee6d3dc88\n",
      "Checking value: 47f9f776c15a87028a6b82e22acfd25c847c0a6d71ebf25749e0244c9957412799cb1eb83055d2c50ab94e2a86b1485e\n",
      "Checking value: 2c05c2c4dd2d3b0b967cd25fc742ac7749c058d79f913340ed51e3950f8abca92ab770ab3d3fd0af8da10b910fc5bfa94e4173891279bd7072ee53aa49d54c00\n",
      "Checking value: 1166678749\n",
      "Checking value: 2131491993515325067\n",
      "Checking value: -5174759824637364236\n",
      "Checking value: 244824896792938886174747607789649131147\n",
      "Checking value: 2016995001\n",
      "Checking value: 1752500392\n",
      "Checking value: 6D795F66756E6E795F686F6E6579\n",
      "Checking value: NV4V6ZTVNZXHSX3IN5XGK6I=\n",
      "Checking value: hFHucvJjLBAotAF5wEG\n",
      "Checking value: bXlfZnVubnlfaG9uZXk=\n",
      "Checking value: my_funny_honey\n",
      "Checking value: hi_my_honey_tex\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['form_text3']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "MY_SENSITIVE_ENCODINGS= {\n",
    "  \"tel\": [\n",
    "    \"34393232313232323030\",\n",
    "    \"GQ4TEMRRGIZDEMBQ\",\n",
    "    \"3wAzuvCkRADzGP\",\n",
    "    \"NDkyMjEyMjIwMA==\",\n",
    "    \"4922122200\",\n",
    "    \"33b134323234323232300000\",\n",
    "    \"789c33b1343232343232323000000b0f01f9\",\n",
    "    \"1f8b080000000000001333b134323234323232300000a3e481680a000000\",\n",
    "    \"00110100001110010011001000110010001100010011001000110010001100100011000000110000\",\n",
    "    \"4922122200\",\n",
    "    \"4922122200\",\n",
    "    \"M7E0MjI0MjIyMAAA\",\n",
    "    \"M7E0MjI0MjIyMAAA\",\n",
    "    \"H4sIAAAAAAAAEzOxNDIyNDIyMjAAAKPkgWgKAAAA\",\n",
    "    \"iwSANDkyMjEyMjIwMAM=\",\n",
    "    \"33b134323234323232300000\",\n",
    "    \"1f8b080000000000001333b134323234323232300000a3e481680a000000\",\n",
    "    \"eJwzsTQyMjQyMjIwAAALDwH5\",\n",
    "    \"4KyE7oGM5oKM4ZiA7K2A\",\n",
    "    \"4KyE7oGM5oKM4ZiA7K2A\",\n",
    "    \"CwTgTGCMFgDLQ\",\n",
    "    \"84d3a0756276940932da44e047086405\",\n",
    "    \"7391027a4dcdd6dfa459dfe85e9cd208f7e70ca7\",\n",
    "    \"e2ddeff7f6379160d21bf08d333a18c7b0a290c974f6451903bfc7d301b7df04\",\n",
    "    \"d8f3d7fe7d03fdacc24d4dfca1bba976cf88450b325d25f93c10ba0f\",\n",
    "    \"208aa443dc30af0140762b17e1f268b628fbc7a18515e68104e22eefe9a9a0e5b8e7e07a6a6b073991e66e7bc49c978d\",\n",
    "    \"e1bf1080654ed05dd2a9c0ad2a2b61113febe705d0981fe82a6d3ff0b4c6fbfde33e8a3d5ec73341f233578d3e75a4a4394a6b3290628b9e684e0719b76f323d\",\n",
    "    \"009700fd326c4896ad286fa000671376eacb78ddddc01c58a4381671\",\n",
    "    \"ffbc43328e658b91b896e1a3dc5218c9549357643504cbe1ebcbe7ea0e865247\",\n",
    "    \"69e26e31d0e4489c1717f7cc215ff3824dd359f2dc9b1cf445962a704cf5c511c878ade2887db1d39bbf5f8094b42f4e\",\n",
    "    \"af33a8963c06306fab91e1466c8eb3da039b7149d351db1db55da38dd4f132c26597161fd0bddf002c430642357c31d92e1981f9775cf8f7acde08c1abe22e28\",\n",
    "    \"2022247329\",\n",
    "    \"-2687720209116599037\",\n",
    "    \"3451519139391771119\",\n",
    "    \"63669290229870245713155212006181530883\",\n",
    "    \"1753343139\",\n",
    "    \"185532921\"\n",
    "  ],\n",
    "  \"password\": [\n",
    "    \"53616C747953656564735465613921\",\n",
    "    \"KNQWY5DZKNSWKZDTKRSWCOJB\",\n",
    "    \"3LJJbd4hWsNsevDznEiiU\",\n",
    "    \"U2FsdHlTZWVkc1RlYTkh\",\n",
    "    \"SaltySeedsTea9%21\",\n",
    "    \"0b4ecc29a90c4e4d4d290e494db4540400\",\n",
    "    \"789c0b4ecc29a90c4e4d4d290e494db45404002ea80576\",\n",
    "    \"1f8b08000000000000130b4ecc29a90c4e4d4d290e494db454040084448f8b0f000000\",\n",
    "    \"010100110110000101101100011101000111100101010011011001010110010101100100011100110101010001100101011000010011100100100001\",\n",
    "    \"SaltySeedsTea9!\",\n",
    "    \"FnyglFrrqfGrn9!\",\n",
    "    \"C07MKakMTk1NKQ5JTbRUBAA=\",\n",
    "    \"C07MKakMTk1NKQ5JTbRUBAA=\",\n",
    "    \"H4sIAAAAAAAAEwtOzCmpDE5NTSkOSU20VAQAhESPiw8AAAA=\",\n",
    "    \"CweAU2FsdHlTZWVkc1RlYTkhAw==\",\n",
    "    \"0b4ecc29a90c4e4d4d290e494db4540400\",\n",
    "    \"1f8b08000000000000130b4ecc29a90c4e4d4d290e494db454040084448f8b0f000000\",\n",
    "    \"eJwLTswpqQxOTU0pDklNtFQEAC6oBXY=\",\n",
    "    \"44qE44C2y6Dpu4DqmrDhjIPjoIXlmKDinIHgooA=\",\n",
    "    \"44qE44C2y6Dpu4DqmrDhjIPjoIXlmKDinIHgooA=\",\n",
    "    \"MoQwNgLgnsCmsBMDOAVWICcBCIA\",\n",
    "    \"4948c713c8f51fcdf341fe5dc5f7f651\",\n",
    "    \"486566dce40fe64622d123079598b9a0bef88551\",\n",
    "    \"2f50045ec0f7fd7ef014aff67338010772fa21226c0b1ca4bb8a596b85a2110f\",\n",
    "    \"2f842ab50309d0bc9db92b5921e71423cc438172313b9e3739669e06\",\n",
    "    \"cb972f03b4d1e1032aecbc095904fd3ce72e0082498eec3fa92b5fa928ca14be586f7838b71c6c7ecde2aedaa2cfe3dc\",\n",
    "    \"d1767a28de17b8862d8d0aebe238048082fa4d43292c941d9e45fee739beea1910d9e528174b0b4597ff9b3b9d0f59eaae00646bb25e74436836b47885bec58c\",\n",
    "    \"12eb75e22875ddf3f4f9df97b55fcdc694a3602ce38b48c03bd709f0\",\n",
    "    \"254b968eda5a4c4ec77b44c5f0c18486b7dcae428586446cc7e32bc4b44efd58\",\n",
    "    \"7f2ea3fbaa3a4655eb902c84e430c2328e98655bb2eba58235067736d62137d923df8578d7dff74439ff42afd8d44ff3\",\n",
    "    \"57ddbf73386b32c4a923a3268ec4837db4e52f84a3eca0b4e2aa6ea1dd87015fe873aa048cb84bf3f3c6790cd1f5dcfadbf67148bbe05f2664f5f6c71702dbdf\",\n",
    "    \"-287875941\",\n",
    "    \"2630329490964472104\",\n",
    "    \"5021836792884838330\",\n",
    "    \"92636538098284972449800741919914713384\",\n",
    "    \"2341422212\",\n",
    "    \"782763382\"\n",
    "  ],\n",
    "  \"form_text\": [\n",
    "    \"68695F6D795F686F6E65795F74657874\",\n",
    "    \"NBUV63LZL5UG63TFPFPXIZLYOQ======\",\n",
    "    \"DtohHfG9wm5HUTLmENZzeX\",\n",
    "    \"aGlfbXlfaG9uZXlfdGV4dA==\",\n",
    "    \"hi_my_hone\"\n",
    "    \"hi_my_honey_text\",\n",
    "    \"cbc88ccfad8ccfc8cf4bad8c2f49ad280100\",\n",
    "    \"789ccbc88ccfad8ccfc8cf4bad8c2f49ad280100387106bd\",\n",
    "    \"1f8b0800000000000013cbc88ccfad8ccfc8cf4bad8c2f49ad2801002ffbe42910000000\",\n",
    "    \"01101000011010010101111101101101011110010101111101101000011011110110111001100101011110010101111101110100011001010111100001110100\",\n",
    "    \"hi_my_honey_text\",\n",
    "    \"uv_zl_ubarl_grkg\",\n",
    "    \"y8iMz62Mz8jPS62ML0mtKAEA\",\n",
    "    \"y8iMz62Mz8jPS62ML0mtKAEA\",\n",
    "    \"H4sIAAAAAAAAE8vIjM+tjM/Iz0utjC9JrSgBAC/75CkQAAAA\",\n",
    "    \"iweAaGlfbXlfaG9uZXlfdGV4dAM=\",\n",
    "    \"cbc88ccfad8ccfc8cf4bad8c2f49ad280100\",\n",
    "    \"1f8b0800000000000013cbc88ccfad8ccfc8cf4bad8c2f49ad2801002ffbe42910000000\",\n",
    "    \"eJzLyIzPrYzPyM9LrYwvSa0oAQA4cQa9\",\n",
    "    \"1oTrg7rgraDpuazgvaDjrILpo4DiuYjequiAgA==\",\n",
    "    \"1oTrg7rgraDpuazgvaDjrILpo4DiuYjequiAgA==\",\n",
    "    \"BYSw+gtgnmwPYDsCmMAuSAeqg\",\n",
    "    \"43e75bec2b6f2c204cb19a21baf28e34\",\n",
    "    \"eea0bb214e955ddb5eef9c486af767e8fbc5cb39\",\n",
    "    \"1ca570fac198727f82d0010004584b693c6e79b65c923acef84bf4169912ea33\",\n",
    "    \"f6823a0e876191719d95ab3023ee076757ad447377d93b47abf36b90\",\n",
    "    \"44ae82b98381ea880d1135c8ffdd52da3764fe1f1bfb693767ed25c4f6fbab8f04f675e43e5adcaa9b2bcdd07ffcda61\",\n",
    "    \"013c9434fcc85dc02d8d50a38fc2f6495173e053b6d57b8071bd35115ff79ef8a03132d77e7e47ef0fc1e7e9873e3ae27c6b64972362751ef01b3443ad7481b3\",\n",
    "    \"80ad41185430a92c32308e71f8d07ed84c6285a05492946e7bc3168d\",\n",
    "    \"047ba5082a889660c46380e777a8ba2ee4e0dd4bbca69a270e67585454125b46\",\n",
    "    \"f55210fbf2e577b3bc36bc961b960fa3963a7be7878309c847f46f0d7cc4d7b968fe0cf18ecc12b54d4fb7680c56c66a\",\n",
    "    \"2c752ade168750df0fb478e5f8eb9fb821af98d367aee0f916402622a7bc343df8840de8a54a5d505ee96d516451ca6949ad37f0a18ad2b9c93057254e3ee0ef\",\n",
    "    \"1753757807\",\n",
    "    \"-2047910037623045259\",\n",
    "    \"3847981994889785074\",\n",
    "    \"70982739059974200961265151179235885941\",\n",
    "    \"702872367\",\n",
    "    \"946931389\"\n",
    "  ],\n",
    "  \"form_text2\": [\n",
    "    \"68695F6D795F686F6E65795F6669656C64\",\n",
    "    \"NBUV63LZL5UG63TFPFPWM2LFNRSA====\",\n",
    "    \"yuf6pXstUhXuiBGECSh1Nzf\",\n",
    "    \"aGlfbXlfaG9uZXlfZmllbGQ=\",\n",
    "    \"hi_my_honey_field\",\n",
    "    \"cbc88ccfad8ccfc8cf4bad8c4fcb4ccd490100\",\n",
    "    \"789ccbc88ccfad8ccfc8cf4bad8c4fcb4ccd4901003f1306fc\",\n",
    "    \"1f8b0800000000000013cbc88ccfad8ccfc8cf4bad8c4fcb4ccd4901004e4036f511000000\",\n",
    "    \"0110100001101001010111110110110101111001010111110110100001101111011011100110010101111001010111110110011001101001011001010110110001100100\",\n",
    "    \"hi_my_honey_field\",\n",
    "    \"uv_zl_ubarl_svryq\",\n",
    "    \"y8iMz62Mz8jPS62MT8tMzUkBAA==\",\n",
    "    \"y8iMz62Mz8jPS62MT8tMzUkBAA==\",\n",
    "    \"H4sIAAAAAAAAE8vIjM+tjM/Iz0utjE/LTM1JAQBOQDb1EQAAAA==\",\n",
    "    \"CwiAaGlfbXlfaG9uZXlfZmllbGQD\",\n",
    "    \"cbc88ccfad8ccfc8cf4bad8c4fcb4ccd490100\",\n",
    "    \"1f8b0800000000000013cbc88ccfad8ccfc8cf4bad8c4fcb4ccd4901004e4036f511000000\",\n",
    "    \"eJzLyIzPrYzPyM9LrYxPy0zNSQEAPxMG/A==\",\n",
    "    \"1oTrg7rgraDpuazgvaDjrILpo4DmmKLkgazJpAA=\",\n",
    "    \"1oTrg7rgraDpuazgvaDjrILpo4DmmKLkgazJpAA=\",\n",
    "    \"BYSw+gtgnmwPYDsCmMBmIkBsAmQ\",\n",
    "    \"f505c12230d40a5dd2538d83eedd7da7\",\n",
    "    \"5291e16b1c4f5afef57fb6987b0c838295871e02\",\n",
    "    \"1643c39ff8767f67ee17e7eaf7cb19ce976af8a0b9d3ecc4218111217e372f7d\",\n",
    "    \"b78094ae62a41967e4aa69fd21bee354119d2c56ab68eaffdf197c1c\",\n",
    "    \"3889e1e25d2983e3633edbed592734719c1c6430ec3203aceac3a487129135d20bb2ae1dcd2be66b1fbec52a1c633350\",\n",
    "    \"8b180d4b7d90628533162567bbe3418b2f5520ee7a9de275dd3a0138cf14a7e1893bc8b525bf03772c7328d73e6972686b056b21f2bb03ca2f45c5096b2c9f83\",\n",
    "    \"3a0c7071c21fe32fdb512689ef2e4b16b6ee7f04db7a3df039e49d4b\",\n",
    "    \"de96f137b568833a6f68a4d358ec56bf28e3b1d1d42916a1a0f8afe690c54afe\",\n",
    "    \"86126692cbbf6c0341274afc4c5d98afeca05a7330ef8748d491e87a2df4ae39f01128c6f349f9dccc62e1cd91bd50a9\",\n",
    "    \"23f5e7432d6def6b1517a051f35332f199ea95fae1456242909ca845e977dee52e55110f12ee1ed16cbd139ac0332a7e3e1d0cb60d008e523598e76fa4440cc7\",\n",
    "    \"1248393586\",\n",
    "    \"-6414144220524007930\",\n",
    "    \"-3909599843592213748\",\n",
    "    \"268162979175578004603604889171042938374\",\n",
    "    \"4113973326\",\n",
    "    \"1058211580\"\n",
    "  ],\n",
    "  \"url_1\": [\n",
    "    \"637572696F75732D6361742E636F6D\",\n",
    "    \"MN2XE2LPOVZS2Y3BOQXGG33N\",\n",
    "    \"3nPVd4R2N6xz4UUk2Zzhi\",\n",
    "    \"Y3VyaW91cy1jYXQuY29t\",\n",
    "    \"curious-cat.com\",\n",
    "    \"4b2e2dcacc2f2dd64d4e2cd14bcecf0500\",\n",
    "    \"789c4b2e2dcacc2f2dd64d4e2cd14bcecf0500302d05dd\",\n",
    "    \"1f8b08000000000000134b2e2dcacc2f2dd64d4e2cd14bcecf0500c7c1a0530f000000\",\n",
    "    \"011000110111010101110010011010010110111101110101011100110010110101100011011000010111010000101110011000110110111101101101\",\n",
    "    \"curious-cat.com\",\n",
    "    \"phevbhf-png.pbz\",\n",
    "    \"Sy4tyswvLdZNTizRS87PBQA=\",\n",
    "    \"Sy4tyswvLdZNTizRS87PBQA=\",\n",
    "    \"H4sIAAAAAAAAE0suLcrMLy3WTU4s0UvOzwUAx8GgUw8AAAA=\",\n",
    "    \"CweAY3VyaW91cy1jYXQuY29tAw==\",\n",
    "    \"4b2e2dcacc2f2dd64d4e2cd14bcecf0500\",\n",
    "    \"1f8b08000000000000134b2e2dcacc2f2dd64d4e2cd14bcecf0500c7c1a0530f000000\",\n",
    "    \"eJxLLi3KzC8t1k1OLNFLzs8FADAtBd0=\",\n",
    "    \"44aF54GO4KWg75ig7LiL5LCC4aCF7IG07IqB5rKA\",\n",
    "    \"44aF54GO4KWg75ig7LiL5LCC4aCF7IG07IqB5rKA\",\n",
    "    \"MYVwTglg9iDOC0wCGAXAdMKBbIA\",\n",
    "    \"caf5110f98f91040e84a02862066fa65\",\n",
    "    \"b7027c2cda316afe9530e01130788e901fcb7913\",\n",
    "    \"2d216e6c59d921ffeba58dfff2b8581666172fd57bf6ee6e44ad224cb4b45a78\",\n",
    "    \"897f1d1072385b8da1f8f3ca466d346be023f8eb335192fce69cea70\",\n",
    "    \"a50db105ebf563ca079ecfd786f943a0e0e392b762a387ad129bc3fff3b468cc15e2ededf353c681456551eaa3bd6137\",\n",
    "    \"9a8b60802fe42fb6aae650c391181b1e54c3a0f8efd1a180b4d698f0a6cdeceeb694c0f740cffbf49c75f0634c18283fff3c3380e5710774616b39a68a8c9bbb\",\n",
    "    \"ef2d53be51971fb181b05ac122cd1f67407624fe9b22fd3d062d21b4\",\n",
    "    \"0915e1bf120f2dc9d303b2a2e7a19938bfa1a78921238eb1776d2fbacd25cb5a\",\n",
    "    \"2def97b3ff239ce0096eaa28aa320fa717f2381c7000c46cec7e0fcae6d3f475ea712b5a6b8b5915665b0d82231a5b6c\",\n",
    "    \"cf9b6c7ac1c7f44f3eda22592edd8094e97e5d04b00f830365d024be8ad3f15c559194d8ec5bad598e567b562698ec4fe5a9a363363450b4ed2419564c1be4b8\",\n",
    "    \"-679406168\",\n",
    "    \"2755373884543779069\",\n",
    "    \"-3309345380778307472\",\n",
    "    \"279235719630208140617208984455809515773\",\n",
    "    \"1403044295\",\n",
    "    \"808256989\"\n",
    "  ],\n",
    "  \"url_2\": [\n",
    "    \"68747470733A2F2F637572696F75732D6361742E636F6D\",\n",
    "    \"NB2HI4DTHIXS6Y3VOJUW65LTFVRWC5BOMNXW2===\",\n",
    "    \"3A8evQZovd7B4jbwRyktga3ZR6388nYC\",\n",
    "    \"aHR0cHM6Ly9jdXJpb3VzLWNhdC5jb20=\",\n",
    "    \"https%3A%2F%2Fcurious-cat.com\",\n",
    "    \"cb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500\",\n",
    "    \"789ccb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500687508a8\",\n",
    "    \"1f8b0800000000000013cb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500b9e6387817000000\",\n",
    "    \"0110100001110100011101000111000001110011001110100010111100101111011000110111010101110010011010010110111101110101011100110010110101100011011000010111010000101110011000110110111101101101\",\n",
    "    \"https://curious-cat.com\",\n",
    "    \"uggcf://phevbhf-png.pbz\",\n",
    "    \"yygpKSi20tdPLi3KzC8t1k1OLNFLzs8FAA==\",\n",
    "    \"yygpKSi20tdPLi3KzC8t1k1OLNFLzs8FAA==\",\n",
    "    \"H4sIAAAAAAAAE8soKSkottLXTy4tyswvLdZNTizRS87PBQC55jh4FwAAAA==\",\n",
    "    \"GxYA+MVTFpMaTJJsfhWMQGWKSyTptDo7iE8=\",\n",
    "    \"cb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500\",\n",
    "    \"1f8b0800000000000013cb28292928b6d2d74f2e2dcacc2f2dd64d4e2cd14bcecf0500b9e6387817000000\",\n",
    "    \"eJzLKCkpKLbS108uLcrMLy3WTU4s0UvOzwUAaHUIqA==\",\n",
    "    \"1oHnhIHshpzgroHupaDsmIXngJPohKzgvaTsoJbohITjhIDjqITjgJbsoIA=\",\n",
    "    \"1oHnhIHshpzgroHupaDsmIXngJPohKzgvaTsoJbohITjhIDjqITjgJbsoIA=\",\n",
    "    \"BYFxAcGcC4HpYMYFcBOBLA9kyBaBBDEAOgQwFsg\",\n",
    "    \"c1a8de3f62604990390ff0555a524865\",\n",
    "    \"41982bd1605b895577c73fe915e0d341c880fb60\",\n",
    "    \"c9b19caac3fa71da9addc8270a4769744ea11f2a6a5edc27ebc1c532951cc291\",\n",
    "    \"ed944b6e4b7a5d8d3124a20099f6126f46d398f793b9623229c108e1\",\n",
    "    \"945e4b8f11d001863cc3ad23d239d8405484b673ba7e5f3039c7d55b32e20a72634b478f9a69f9c30beac7becf86ad8e\",\n",
    "    \"938ca936fd2bcdff508bbea2c5665c2d4f618129c41a9fa88ad40917b9402150ee4836d26b1946d357476e0d2c7e1cad32b792faa45740474e0e7cafd94d8ffb\",\n",
    "    \"6c901274c1162a4c9bd9a8580e06b6c2d3e4724ee62bfe89954b81cc\",\n",
    "    \"c1d03e01aaa3442521f7d9d45fbbc02e38ce550103ac44303f511ffee6d3dc88\",\n",
    "    \"47f9f776c15a87028a6b82e22acfd25c847c0a6d71ebf25749e0244c9957412799cb1eb83055d2c50ab94e2a86b1485e\",\n",
    "    \"2c05c2c4dd2d3b0b967cd25fc742ac7749c058d79f913340ed51e3950f8abca92ab770ab3d3fd0af8da10b910fc5bfa94e4173891279bd7072ee53aa49d54c00\",\n",
    "    \"1166678749\",\n",
    "    \"2131491993515325067\",\n",
    "    \"-5174759824637364236\",\n",
    "    \"244824896792938886174747607789649131147\",\n",
    "    \"2016995001\",\n",
    "    \"1752500392\"\n",
    "  ],\n",
    "  \"form_text3\": [\n",
    "    \"6D795F66756E6E795F686F6E6579\",\n",
    "    \"NV4V6ZTVNZXHSX3IN5XGK6I=\",\n",
    "    \"hFHucvJjLBAotAF5wEG\",\n",
    "    \"bXlfZnVubnlfaG9uZXk=\",\n",
    "    \"my_funny_honey\",\n",
    "    \"hi_my_honey_tex\",\n",
    "    \"cbad8c4f2bcdcbab8ccfc8cf4bad0400\",\n",
    "    \"789ccbad8c4f2bcdcbab8ccfc8cf4bad04002cb905f8\",\n",
    "    \"1f8b0800000000000013cbad8c4f2bcdcbab8ccfc8cf4bad0400ef8be65d0e000000\",\n",
    "    \"0110110101111001010111110110011001110101011011100110111001111001010111110110100001101111011011100110010101111001\",\n",
    "    \"my_funny_honey\",\n",
    "    \"zl_shaal_ubarl\",\n",
    "    \"y62MTyvNy6uMz8jPS60EAA==\",\n",
    "    \"y62MTyvNy6uMz8jPS60EAA==\",\n",
    "    \"H4sIAAAAAAAAE8utjE8rzcurjM/Iz0utBADvi+ZdDgAAAA==\",\n",
    "    \"iwaAbXlfZnVubnlfaG9uZXkD\",\n",
    "    \"cbad8c4f2bcdcbab8ccfc8cf4bad0400\",\n",
    "    \"1f8b0800000000000013cbad8c4f2bcdcbab8ccfc8cf4bad0400ef8be65d0e000000\",\n",
    "    \"eJzLrYxPK83Lq4zPyM9LrQQALLkF+A==\",\n",
    "    \"4raE74O62aDquIfmj6DgrIPto4DqmKIA\",\n",
    "    \"4raE74O62aDquIfmj6DgrIPto4DqmKIA\",\n",
    "    \"LYTw+gZgrgdj4AsD2MCmIg\",\n",
    "    \"30247d2340349e67ba677a358aeb51c2\",\n",
    "    \"f85059d378904b17af1af3dffd1c006eb3a0d5a9\",\n",
    "    \"dbd3135a7d724f50502c59fe740c4129ccf538b3b0a936a9aa0323e867f86cbb\",\n",
    "    \"a34d74db44abd71b5f546ab366494f2cc808c2121f898d436e02c457\",\n",
    "    \"99b4ff2d3c53f20a5a1815bcabeed1cfc66659fb0e9a960981ff981e4a7b808a496ec646ff1d9e7893dc7b5ed845ff11\",\n",
    "    \"1691253552841a376371107fdf3628b9432dac01a05f3cc041875adeedddba886fd0765d9dac2e565452d82d5fb1d9602d4d971f7b74da71ae7eef0610f91270\",\n",
    "    \"31be1bb1e2a65f888b19aafe249c9131d62508aacd81981593218561\",\n",
    "    \"dbaa7e4a281ef017b87ab8afab5bd2b4f741e94a1106d2a6a97fd75d8550ac6e\",\n",
    "    \"e34c0002d6a3da03d275ee17afd512629a95bef472bbe16272212d490c1b90ed037cc8821beea3283c260844f15bbda3\",\n",
    "    \"373297e145c92a81a9de0216cf2cba7acd4626dd0537afead6e1db2c37b634e6f4c19ad59382959398f992c60207467b80a6339bcb2848a516f7eeff26f70cee\",\n",
    "    \"-1229217392\",\n",
    "    \"-8568163609771675660\",\n",
    "    \"-511827998734884535\",\n",
    "    \"330840806818517112295286193563323428852\",\n",
    "    \"1575390191\",\n",
    "    \"750323192\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "MIN_LENGTH_OF_FIELD = 10 # Minimum length of field to be considered a token\n",
    "\n",
    "def find_matches(sensitive_dict, candidates):\n",
    "    matches = set()\n",
    "    candidate_strs = list(map(str, candidates))  # Ensure all are strings\n",
    "    concatenated = ' '.join(candidate_strs)      # Concatenate once for faster lookup\n",
    "\n",
    "    print(type(concatenated))\n",
    "    print('------')\n",
    "    print('------')\n",
    "    print('------')\n",
    "    print(\"*********\")\n",
    "    print(\"*********\")\n",
    "    print(\"*********\") \n",
    "    \n",
    "    for key, values in sensitive_dict.items():\n",
    "        for val in values:\n",
    "            val_str = str(val)\n",
    "            print(f\"Checking value: {val_str}\")\n",
    "            if val_str in concatenated:\n",
    "                if isinstance(key, (str, int, float)):\n",
    "                    matches.add(str(key))\n",
    "                else:\n",
    "                    print(f\"Skipping unhashable key: {key} (type: {type(key)})\")\n",
    "                break  # No need to check more values for this key\n",
    "    return list(matches)\n",
    " \n",
    "candidates = [\"\"\"\n",
    "Concatenated candidates: eJxdjEsasdsadOhDAMQ /idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4 eJxdjEsasdsadOhDAMQ+/idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v+TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4 rWkqwRfnfqfnqBuQNZD+/vqELmmNvIKXJXdtdXDBJm4PZD4h4RAvOJpJj/J5i+GsVykNX0bF7NzFT04AV3D1NIjIL0O2ZOVp/OU331TYZYasjiVIl4I9srX16M2GqGHT5JKqJhKI3Iq2S1L1vjl2Zttx7z3ER5NP6NYj4 86db69b3ffe6a27a2b6a295e7607ac868a627f2b2f71ca26fee9ecb5a6e57bfa6ba1db9c79b6ad721789c5d8c4b1ab1db1a74e84300c43efe2751633cc08955ca58aaa0a8a40e5b3e02310e2ee04362056716c3f5b9bfe4df225c402b4a12ec09921b4e0d237435015c1563407630121cfc11f7df518b30b9dfc2f215cb857d7de2b5e99d93753506e565dd5ae5d5dd57761756358b0cb6320824ee6dd1139002e802f0e https://monorail-edge.shopifysvc.com/unstable/produce_batch?eJxdjEsasdsadOhDAMQ /idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4= https://monorail-edge.shopifysvc.com/unstable/produce_batch?eJxdjEsasdsadOhDAMQ+/idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v+TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4= uggcf://zbabenvy-rqtr.fubcvslfip.pbz/hafgnoyr/cebqhpr_ongpu?rWkqwRfnfqfnqBuQNZD+/vqELmmNvIKXJXdtdXDBJm4PZD4h4RAvOJpJj/J5i+GsVykNX0bF7NzFT04AV3D1NIjIL0O2ZOVp/OU331TYZYasjiVIl4I9srX16M2GqGHT5JKqJhKI3Iq2S1L1vjl2Zttx7z3ER5NP6NYj4= a6ba1db9c79b6ad721 produce_batch cebqhpr_ongpu eJxdjEsasdsadOhDAMQ /idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4= eJxdjEsasdsadOhDAMQ+/idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v+TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4= rWkqwRfnfqfnqBuQNZD+/vqELmmNvIKXJXdtdXDBJm4PZD4h4RAvOJpJj/J5i+GsVykNX0bF7NzFT04AV3D1NIjIL0O2ZOVp/OU331TYZYasjiVIl4I9srX16M2GqGHT5JKqJhKI3Iq2S1L1vjl2Zttx7z3ER5NP6NYj4= 6acb1a75e27176312c3a10c0310fbf89d458cf30225572962aa82a290396cf808c438bb810d88159c5b0fd6e6ff937c897100ad284bb026486d38348dd0d40570558d01d8c04873f047df7d462cc2e77f0bc8572e15f5f78ad7a6764dd4d41b9597756b9757755dd85d58d62c32d8c82093b9b7444e400ba00bc38 assad=eJxdjEsOhDAMQ /idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4= assad=eJxdjEsOhDAMQ+/idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v+TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4= nffnq=rWkqwRfBuQNZD+/vqELmmNvIKXJXdtdXDBJm4PZD4h4RAvOJpJj/J5i+GsVykNX0bF7NzFT04AV3D1NIjIL0O2ZOVp/OU331TYZYasjiVIl4I9srX16M2GqGHT5JKqJhKI3Iq2S1L1vjl2Zttx7z3ER5NP6NYj4= 789c5d8c4b0e84300c43efe2751633cc08955ca58aaa0a8a40e5b3e02310e2ee04362056716c3f5b9bfe4df225c402b4a12ec09921b4e0d237435015c1563407630121cfc11f7df518b30b9dfc2f215cb857d7de2b5e99d93753506e565dd5ae5d5dd57761756358b0cb6320824ee6dd1139002e802f0e eJxdjEsOhDAMQ /idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4= eJxdjEsOhDAMQ+/idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v+TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4= rWkqwRfBuQNZD+/vqELmmNvIKXJXdtdXDBJm4PZD4h4RAvOJpJj/J5i+GsVykNX0bF7NzFT04AV3D1NIjIL0O2ZOVp/OU331TYZYasjiVIl4I9srX16M2GqGHT5JKqJhKI3Iq2S1L1vjl2Zttx7z3ER5NP6NYj4= [[64821,\"kd\",{\"id\":98,\"m\":false,\"mk\":[],\"k\":\"x\",\"cc\":0,\"kc\":88}],[64832,\"d\",{\"ac\":[{\"id\":98,\"a\":\"value\",\"v\":\"hi_my_honey_tex\"}]}],[64832,\"k\",98,\"hi_my_honey_tex\"]] ['6acb1a75e27176312c3a10c0310fbf89d458cf30225572962aa82a290396cf808c438bb810d88159c5b0fd6e6ff937c897100ad284bb026486d38348dd0d40570558d01d8c04873f047df7d462cc2e77f0bc8572e15f5f78ad7a6764dd4d41b9597756b9757755dd85d58d62c32d8c82093b9b7444e400ba00bc38', 'assad=eJxdjEsOhDAMQ /idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4=', 'assad=eJxdjEsOhDAMQ+/idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v+TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4=', 'nffnq=rWkqwRfBuQNZD+/vqELmmNvIKXJXdtdXDBJm4PZD4h4RAvOJpJj/J5i+GsVykNX0bF7NzFT04AV3D1NIjIL0O2ZOVp/OU331TYZYasjiVIl4I9srX16M2GqGHT5JKqJhKI3Iq2S1L1vjl2Zttx7z3ER5NP6NYj4='] https://monorail-edge.shopifysvc.com/unstable/produce_batch?eJxdjEsasdsadOhDAMQ+/idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v+TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4= assad=eJxdjEsOhDAMQ+/idRYzzAiVXKWKqgqKQOWz4CMQ4u4ENiBWcWw/W5v+TfIlxAK0oS7AmSG04NI3Q1AVwVY0B2MBIc/BH331GLMLnfwvIVy4V9feK16Z2TdTUG5WXdWuXV3Vd2F1Y1iwy2Mggk7m3RE5AC6ALw4=\n",
    "\"\"\"]\n",
    "\n",
    "find_matches(MY_SENSITIVE_ENCODINGS, candidates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
